{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sprint_08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiguozhe01/DIC_Assignment/blob/master/Sprint_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmbYvx8vD5Eb"
      },
      "source": [
        "# Sprint アンサンブル学習\n",
        "\n",
        "## 【考察】\n",
        "\n",
        "**アンサンブル学習とは・・・**\\\n",
        "複数の学習モデルを組み合わせる手法。\n",
        "* 下階層：ベースモデル（base/weak learner/ genelizer）\n",
        "* 上階層：メタモデル（meta learner/stacker）\n",
        "\n",
        "-----------------------------------------------------------------------\n",
        "\n",
        "* バギング：訓練データを分割して、複数の決定木モデルの推定値を評価する方法。\n",
        "* ブレンディング：複数のモデルの推定値を使って評価する方法\n",
        "* スタッキング：ブレンディングとバギングのハイブリッド手法。複数のモデルを用い、訓練データを分割して評価する方法。\n",
        "\n",
        "(Bagging)\n",
        "        * for 決定木\n",
        "        * 過学習（訓練データに過剰適合しがち）\n",
        "        * so 汎化誤差（generalization error）を減らしたい。\n",
        "        * generalization error = variance（モデルの複雑さ）+ bias（真の関数とモデルのずれ）** 2 + noise\n",
        "        * therefore Baggingが提案される。（単一の決定木だと高くなりがちなvarianceを下げる事ができる。\n",
        "            1. 訓練データから離散一様分布に従い、ランダムな標本再抽出（bootstrap sampling）\n",
        "            2. 分割した各サブセットに対して決定木を当てはめ、複数の決定木の結果を得る。\n",
        "            3. 最後に多数決（回帰ならば平均）を行う。\n",
        "            4. そもそも上記のアルゴリズムに特徴量サンプリングも追加して、RandomForestとなる。\n",
        "            \n",
        "        * for RandomForest\n",
        "        * bootstrap法で作成した各々の決定木同士の相関 > 分岐で異なる特徴量を選ぶ決定木を生成するRandomForest\n",
        "        * 結果、RandomForestだとvariance（分散）が下がり、Baggingより汎化性能（未知のテストデータに対する識別能力）が高くなる。\n",
        "\n",
        "(Blending)\n",
        "        * Bagging/RandomForestと違い、異なる予測モデルを組み合わせる。\n",
        "            * 異なる予測モデル、特徴量、訓練データ、パラメータ（多数決、平均値、最大値、最小値 etc）\n",
        "            \n",
        "(Stacking)\n",
        "        * 予測モデルの積み重ね。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA4ZEo8jD5Ec"
      },
      "source": [
        "疑問点\n",
        "* 説明変数をsplitしたが、目的変数もsplitが必要ではないのか？\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYZFM3rXD5Ed"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# データ分割用\n",
        "from sklearn.model_selection import train_test_split\n",
        "# MSE算出用\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# 線形回帰用\n",
        "from sklearn import datasets, linear_model\n",
        "# 決定木用\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# SVR用\n",
        "from sklearn.svm import SVR\n",
        "# ロジスティック回帰用\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# ランダムフォレスト用\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# 主成分分析器用\n",
        "from sklearn.decomposition import PCA \n",
        "# 標準化用\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# 標準化と学習モデルを一元化するため\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vluUl2wD5Eh"
      },
      "source": [
        "## データセットの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVXgit5YD5Eh"
      },
      "source": [
        "# csvファイルを読み込む\n",
        "data_set = pd.read_csv('..\\Week4\\house_prices_train.csv')\n",
        "\n",
        "# 目的変数と説明変数とで区分する。\n",
        "input_data = data_set[[\"GrLivArea\", \"YearBuilt\"]]\n",
        "target_data = data_set[[\"SalePrice\"]]\n",
        "\n",
        "# 説明変数を8:2で分割する。\n",
        "input_train, input_test = train_test_split(input_data, test_size=0.2, random_state=0)\n",
        "\n",
        "# 目的変数を8:2で分割する。\n",
        "target_train, target_test = train_test_split(target_data, test_size=0.2, random_state=0)\n",
        "\n",
        "########\n",
        "# 標準化のインスタンス化\n",
        "sscaler = preprocessing.StandardScaler()\n",
        "sscaler_input = sscaler.fit(input_train)\n",
        "input_train_ss = sscaler_input.transform(input_train)\n",
        "input_test_ss = sscaler_input.transform(input_test)\n",
        "\n",
        "sscaler_target = sscaler.fit(target_train)\n",
        "target_train_ss = sscaler_target.transform(target_train)\n",
        "target_test_ss = sscaler_target.transform(target_test)\n",
        "########\n",
        "\n",
        "# 主成分分析\n",
        "pca = PCA()\n",
        "pca_default = pca.fit(input_train)\n",
        "pca_ss = pca.fit(input_train_ss)\n",
        "\n",
        "input_train_pca = pca_default.transform(input_train)\n",
        "input_train_ss_pca = pca_ss.transform(input_train_ss)\n",
        "\n",
        "input_test_pca = pca_default.transform(input_test)\n",
        "input_test_ss_pca = pca_ss.transform(input_test_ss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdexDmjvD5Ek"
      },
      "source": [
        "# 【問題1】ブレンディングのスクラッチ実装\n",
        "\n",
        "ブレンディングを3通りスクラッチ実装せよ。\n",
        "\n",
        "* 比較対象として、単一モデルも用意する。\n",
        "* 比較数値は精度の上下\n",
        "    * 例）精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さいこと。\n",
        "----------    \n",
        "    \n",
        "**比較3通り**\n",
        "\n",
        "1. ロジスティック回帰 vs ロジスティック回帰（標準化）\n",
        "2. ロジスティック回帰 vs ロジスティック回帰（標準化+主成分分析）\n",
        "3. ロジスティック回帰 vs ロジスティック回帰 & 線形回帰 & 決定木 & SVR（線形カーネル）& ランダムフォレスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUtvmNMZD5Ek"
      },
      "source": [
        "## 線形回帰モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqyqq3NdD5Ek",
        "outputId": "16e57b53-1ed3-4d25-876e-7a463e626bfa"
      },
      "source": [
        "# コントロール対照\n",
        "# 線形回帰モデルをインスタンス化\n",
        "linear_regr = linear_model.LinearRegression()\n",
        "linear_regr_ss = linear_model.LinearRegression()\n",
        "linear_regr_ss_pca = linear_model.LinearRegression()\n",
        "\n",
        "# モデルを学習させる。\n",
        "linear_regr.fit(input_train, target_train)\n",
        "linear_regr_ss.fit(input_train_ss, target_train)\n",
        "linear_regr_ss_pca.fit(input_train_ss_pca, target_train)\n",
        "\n",
        "# 学習後のモデルを用い、推測を行う。\n",
        "target_predict = linear_regr.predict(input_test)\n",
        "target_predict_ss = linear_regr_ss.predict(input_test_ss)\n",
        "target_predict_ss_pca = linear_regr_ss_pca.predict(input_test_ss_pca)\n",
        "\n",
        "\n",
        "# MSEを算出する前に、推測結果の平均値を出す！！！\n",
        "# The mean squared error\n",
        "linear_regr_mse = mean_squared_error(target_test, target_predict)\n",
        "linear_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
        "linear_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
        "\n",
        "print('線形回帰の平均二乗誤差（MSE）は: %.5e'% linear_regr_mse)\n",
        "print('線形回帰の標準化済み平均二乗誤差（MSE）は：%.5e'% linear_regr_ss_mse)\n",
        "print('線形回帰の標準化+PCA済み平均二乗誤差（MSE）は：%.5e'% linear_regr_ss_pca_mse)\n",
        "\n",
        "# plot outputs\n",
        "#\n",
        "# plt.scatter(input_test.iloc[:,0], target_test, color='black')\n",
        "# plt.plot(input_test.iloc[:,0].sort_values(), np.sort(target_predict, axis=0), color='blue', linewidth=3)\n",
        "#\n",
        "# plt.xticks(())\n",
        "# plt.yticks(())\n",
        "# plt.title('GrLivArea vs SalePrice')\n",
        "#\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "線形回帰の平均二乗誤差（MSE）は: 2.94207e+09\n",
            "線形回帰の標準化済み平均二乗誤差（MSE）は：2.94207e+09\n",
            "線形回帰の標準化+PCA済み平均二乗誤差（MSE）は：2.94207e+09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fBlhreQD5En"
      },
      "source": [
        "## 決定木モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdm6EXUID5En",
        "outputId": "2f512a29-5bd9-4c70-fde5-0de10171cb98"
      },
      "source": [
        "# 決定木（回帰）のMSEを算出\n",
        "\n",
        "# 決定木モデルをインスタンス化\n",
        "tree_regr = DecisionTreeRegressor(random_state=0)\n",
        "tree_regr_ss = DecisionTreeRegressor(random_state=0)\n",
        "tree_regr_ss_pca = DecisionTreeRegressor(random_state=0)\n",
        "\n",
        "# モデルを学習させる。\n",
        "tree_regr.fit(input_train, target_train)\n",
        "tree_regr_ss.fit(input_train_ss, target_train)\n",
        "tree_regr_ss_pca.fit(input_train_ss_pca, target_train)\n",
        "\n",
        "# 学習後のモデルを用い、推測を行う。\n",
        "target_predict = tree_regr.predict(input_test)\n",
        "target_predict_ss = tree_regr_ss.predict(input_test_ss)\n",
        "target_precict_ss_pca = tree_regr_ss_pca.predict(input_test_ss_pca)\n",
        "\n",
        "# The mean squared error\n",
        "tree_regr_mse = mean_squared_error(target_test, target_predict)\n",
        "tree_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
        "tree_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
        "\n",
        "print(f'決定木（回帰）の平均二乗誤差（MSE）は:{tree_regr_mse: .5e}')\n",
        "print(f'決定木（回帰）の標準化済み平均二乗誤差（MSE）は：%.5e'% tree_regr_ss_mse)\n",
        "print(f'決定木（回帰）の標準化+PCA済み平均二乗誤差（MSE）は：%.5e'% tree_regr_ss_pca_mse)\n",
        "\n",
        "# plt.scatter(input_test.iloc[:,0], target_test, color='black')\n",
        "# plt.plot(input_test.iloc[:,0].sort_values(), np.sort(target_predict, axis=0), color='blue', linewidth=3)\n",
        "\n",
        "# plt.xticks(())\n",
        "# plt.yticks(())\n",
        "# plt.title('GrLivArea vs SalePrice')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "決定木（回帰）の平均二乗誤差（MSE）は: 3.00917e+09\n",
            "決定木（回帰）の標準化済み平均二乗誤差（MSE）は：3.01586e+09\n",
            "決定木（回帰）の標準化+PCA済み平均二乗誤差（MSE）は：2.94207e+09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyG0wlLyD5Ep"
      },
      "source": [
        "## SVRモデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3FzpBX-D5Eq",
        "outputId": "94fc982d-8f1e-4f20-c070-607d757c234d"
      },
      "source": [
        "# SVRのMSEを算出\n",
        "\n",
        "# SVRモデルをインスタンス化\n",
        "sv_regr = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
        "sv_regr_pca = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
        "sv_regr_ss = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
        "sv_regr_ss_pca = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
        "\n",
        "# モデルを学習させる。\n",
        "sv_regr.fit(input_train, target_train.iloc[:, 0]) # SVR的に学習する際の目的変数は1dが望ましいので、pandas.series化する。\n",
        "sv_regr_pca.fit(input_train_pca, target_train.iloc[:, 0])\n",
        "sv_regr_ss.fit(input_train_ss, target_train.iloc[:, 0])\n",
        "sv_regr_ss_pca.fit(input_train_ss_pca, target_train.iloc[:, 0])\n",
        "\n",
        "\n",
        "# 学習後のモデルを用い、推測を行う。\n",
        "target_predict = sv_regr.predict(input_test)\n",
        "target_predict_pca = sv_regr_pca.predict(input_test_pca)\n",
        "target_predict_ss = sv_regr_ss.predict(input_test_ss)\n",
        "target_predict_ss_pca = sv_regr_ss_pca.predict(input_test_ss_pca)\n",
        "\n",
        "# The mean squared error\n",
        "sv_regr_mse = mean_squared_error(target_test, target_predict)\n",
        "sv_regr_pca_mse = mean_squared_error(target_test, target_predict)\n",
        "sv_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
        "sv_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
        "\n",
        "print(f'SVRの平均二乗誤差（MSE）は:{sv_regr_mse: .3e}')\n",
        "print(f'SVRのPCA済み平均二乗誤差（MSE）は：{sv_regr_pca_mse: .3e}')\n",
        "print(f'SVRの標準化済み平均二乗誤差（MSE）は：%.3e'% sv_regr_ss_mse)\n",
        "print(f'SVRの標準化+PCA済み平均二乗誤差（MSE）は：%.3e'% sv_regr_ss_pca_mse)\n",
        "\n",
        "\n",
        "# plt.scatter(input_test.iloc[:,0], target_test, color='black')\n",
        "# plt.plot(input_test.iloc[:,0].sort_values(), np.sort(target_predict, axis=0), color='blue', linewidth=3)\n",
        "\n",
        "# plt.xticks(())\n",
        "# plt.yticks(())\n",
        "# plt.title('GrLivArea vs SalePrice')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVRの平均二乗誤差（MSE）は: 2.942e+09\n",
            "SVRのPCA済み平均二乗誤差（MSE）は： 2.942e+09\n",
            "SVRの標準化済み平均二乗誤差（MSE）は：7.092e+09\n",
            "SVRの標準化+PCA済み平均二乗誤差（MSE）は：7.092e+09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wkevZrD5Es"
      },
      "source": [
        "## ロジスティック回帰モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H39YDwW8D5Es",
        "outputId": "c872c1ae-3dbc-4e17-8a15-d2c5f1396b14"
      },
      "source": [
        "# ロジスティック回帰のMSEを算出\n",
        "\n",
        "# ロジスティック回帰モデルをインスタンス化\n",
        "log_regr = LogisticRegression(random_state=0)\n",
        "log_regr_ss = LogisticRegression(random_state=0)\n",
        "log_regr_ss_pca = LogisticRegression(random_state=0)\n",
        "\n",
        "# モデルを学習させる。\n",
        "log_regr.fit(input_train, target_train.iloc[:, 0])\n",
        "log_regr_ss.fit(input_train_ss, target_train.iloc[:, 0])\n",
        "log_regr_ss_pca.fit(input_train_ss_pca, target_train.iloc[:, 0])\n",
        "\n",
        "# 学習後のモデルを用い、推測を行う。\n",
        "target_predict = log_regr.predict(input_test)\n",
        "target_predict_ss = log_regr_ss.predict(input_test_ss)\n",
        "target_predict_ss_pca = log_regr_ss.predict(input_test_ss_pca)\n",
        "\n",
        "# The mean squared error\n",
        "log_regr_mse = mean_squared_error(target_test, target_predict)\n",
        "log_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
        "log_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
        "\n",
        "print(f'ロジスティック回帰の平均二乗誤差（MSE）は:{log_regr_mse: .3e}')\n",
        "print(f'ロジスティック回帰の標準化済み平均二乗誤差（MSE）は：%.3e'% log_regr_ss_mse)\n",
        "print(f'ロジスティック回帰の標準化+PCA済み平均二乗誤差（MSE）は：%.3e'% log_regr_ss_pca_mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ロジスティック回帰の平均二乗誤差（MSE）は: 5.471e+09\n",
            "ロジスティック回帰の標準化済み平均二乗誤差（MSE）は：3.836e+09\n",
            "ロジスティック回帰の標準化+PCA済み平均二乗誤差（MSE）は：4.878e+09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdzmbPI1D5Ev"
      },
      "source": [
        "## ランダムフォレストモデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rut7Gk0fD5Ev",
        "outputId": "04d6c7f5-ba7c-4a1d-a9e2-12d1745c1bca"
      },
      "source": [
        "# ランダムフォレストのMSEを算出\n",
        "\n",
        "# ランダムフォレストモデルをインスタンス化\n",
        "forest_regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "forest_regr_ss = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "forest_regr_ss_pca = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "\n",
        "# モデルを学習させる。\n",
        "forest_regr.fit(input_train, target_train.iloc[:, 0])\n",
        "forest_regr_ss.fit(input_train_ss, target_train.iloc[:, 0])\n",
        "forest_regr_ss_pca.fit(input_train_ss_pca, target_train.iloc[:, 0])\n",
        "\n",
        "# 学習後のモデルを用い、推測を行う。\n",
        "forest_target_predict = forest_regr.predict(input_test)\n",
        "forest_target_predict_ss = forest_regr_ss.predict(input_test_ss)\n",
        "forest_target_predict_ss_pca = forest_regr_ss_pca.predict(input_test_ss_pca)\n",
        "\n",
        "# The mean squared error\n",
        "forest_regr_mse = mean_squared_error(target_test, forest_target_predict)\n",
        "forest_regr_ss_mse = mean_squared_error(target_test, forest_target_predict_ss)\n",
        "forest_regr_ss_pca_mse = mean_squared_error(target_test, forest_target_predict_ss_pca)\n",
        "\n",
        "print(f'ランダムフォレストの平均二乗誤差（MSE）は:{forest_regr_mse: .3e}')\n",
        "print(f'ランダムフォレストの標準化済み平均二乗誤差（MSE）は：%.3e'% forest_regr_ss_mse)\n",
        "print(f'ランダムフォレストの標準化+PCA済み平均二乗誤差（MSE）は%.3e'% forest_regr_ss_pca_mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ランダムフォレストの平均二乗誤差（MSE）は: 2.959e+09\n",
            "ランダムフォレストの標準化済み平均二乗誤差（MSE）は：2.956e+09\n",
            "ランダムフォレストの標準化+PCA済み平均二乗誤差（MSE）は2.474e+09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrNjgKFtD5Ex"
      },
      "source": [
        "## 全モデルの作表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JMf3vSWjD5Ex",
        "outputId": "69f68e1c-db2a-456d-a4ea-b602783a3549"
      },
      "source": [
        "df = pd.DataFrame(np.zeros(15).reshape(5, 3),\n",
        "                 columns=['default', 'sscaler', 'sscaler+PCA'],\n",
        "                 index=['linear_reg', 'tree', 'SVR', 'log_reg', 'forest'])\n",
        "df.loc['linear_reg'] = [linear_regr_mse, linear_regr_ss_mse, linear_regr_ss_pca_mse]\n",
        "df.loc['tree'] = [tree_regr_mse, tree_regr_ss_mse, tree_regr_ss_pca_mse]\n",
        "df.loc['SVR'] = [sv_regr_mse, sv_regr_ss_mse, sv_regr_ss_pca_mse]\n",
        "df.loc['log_reg'] = [log_regr_mse, log_regr_ss_mse, log_regr_ss_pca_mse]\n",
        "df.loc['forest'] = [forest_regr_mse, forest_regr_ss_mse, forest_regr_ss_pca_mse]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>default</th>\n",
              "      <th>sscaler</th>\n",
              "      <th>sscaler+PCA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>linear_reg</th>\n",
              "      <td>2.942067e+09</td>\n",
              "      <td>2.942067e+09</td>\n",
              "      <td>2.942067e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tree</th>\n",
              "      <td>3.009170e+09</td>\n",
              "      <td>3.015860e+09</td>\n",
              "      <td>2.942067e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>2.941629e+09</td>\n",
              "      <td>7.092013e+09</td>\n",
              "      <td>7.092013e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log_reg</th>\n",
              "      <td>5.471145e+09</td>\n",
              "      <td>3.836195e+09</td>\n",
              "      <td>4.878052e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forest</th>\n",
              "      <td>2.958781e+09</td>\n",
              "      <td>2.956401e+09</td>\n",
              "      <td>2.473558e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 default       sscaler   sscaler+PCA\n",
              "linear_reg  2.942067e+09  2.942067e+09  2.942067e+09\n",
              "tree        3.009170e+09  3.015860e+09  2.942067e+09\n",
              "SVR         2.941629e+09  7.092013e+09  7.092013e+09\n",
              "log_reg     5.471145e+09  3.836195e+09  4.878052e+09\n",
              "forest      2.958781e+09  2.956401e+09  2.473558e+09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIzpahHVD5Ez"
      },
      "source": [
        "## 結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPSqsoVsD5Ez",
        "outputId": "fa87b77f-ea3d-483b-f65f-a270686feb2a"
      },
      "source": [
        "# コントロール対象\n",
        "print('ロジスティック回帰の平均二乗誤差（MSE）は: %.3e'% log_regr_mse)\n",
        "\n",
        "# ロジスティック回帰前の標準化\n",
        "print('比較対象①ロジスティック回帰（標準化）のMSEは：%.3e'% log_regr_ss_mse)\n",
        "\n",
        "# ロジスティック回帰前に標準化と主成分分析\n",
        "print('比較対象②ロジスティック回帰（標準化+主成分分析）の平均MSEは：%.3e'% log_regr_ss_pca_mse)\n",
        "\n",
        "# 線形回帰+決定木+SVR+ロジスティック回帰+ランダムフォレストの平均MSE\n",
        "set_3 = linear_regr_mse, tree_regr_mse, sv_regr_mse, log_regr_mse, forest_regr_mse\n",
        "print('比較対象③ロジスティック回帰 & 線形回帰 & 決定木 & SVR（線形カーネル）& ランダムフォレストの平均MSEは：%.3e'% np.mean(set_3))\n",
        "print()\n",
        "print(\"結論：線形回帰のみのモデルがMSE値も低くかった。\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ロジスティック回帰の平均二乗誤差（MSE）は: 5.471e+09\n",
            "比較対象①ロジスティック回帰（標準化）のMSEは：3.836e+09\n",
            "比較対象②ロジスティック回帰（標準化+主成分分析）の平均MSEは：4.878e+09\n",
            "比較対象③ロジスティック回帰 & 線形回帰 & 決定木 & SVR（線形カーネル）& ランダムフォレストの平均MSEは：3.465e+09\n",
            "\n",
            "結論：線形回帰のみのモデルがMSE値も低くかった。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9azS7-FjD5E1"
      },
      "source": [
        "# 【問題2】バギングのスクラッチ実装\n",
        "\n",
        "バギングをスクラッチ実装せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uEIpNWVExlv"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from numpy import random\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TESFxKTzFl0C",
        "outputId": "0f9eb0b2-9d67-4c5c-f2e4-8496bda43a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ3qrSZEFV2L",
        "outputId": "cd66ac9d-008a-4b24-992e-7d4ae1b75fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "house_data = pd.read_csv('/content/drive/My Drive/DIC/dataset/House_Prices/house_prices_train.csv')\n",
        "np.set_printoptions(suppress=True)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "#GrLivArea、YearBuilt、SalePriceを抽出\n",
        "train = house_data.loc[:, ['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1710</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1786</td>\n",
              "      <td>2001</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1717</td>\n",
              "      <td>1915</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2198</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   GrLivArea  YearBuilt  SalePrice\n",
              "0       1710       2003     208500\n",
              "1       1262       1976     181500\n",
              "2       1786       2001     223500\n",
              "3       1717       1915     140000\n",
              "4       2198       2000     250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDbt9QKXMJpM"
      },
      "source": [
        "# Blendingクラスの実装\n",
        "\n",
        "class Blending():\n",
        "    def __init__(self, model_list=None):\n",
        "        self.model_list = model_list\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        for model in self.model_list:\n",
        "            model.fit(X, y)\n",
        "            \n",
        "    def predict(self, X, metric='mean', weight=None):\n",
        "        \n",
        "        preds = np.empty((len(X), len(self.model_list)))\n",
        "        \n",
        "        for i, model in enumerate(self.model_list):\n",
        "            preds[:, i] = model.predict(X)\n",
        "        \n",
        "        \n",
        "        if metric == 'mean':\n",
        "            return preds.mean(axis=1)\n",
        "        elif metric == 'median':\n",
        "            return np.median(preds, axis=1)\n",
        "        elif metric == 'max':\n",
        "            return preds.max(axis=1)\n",
        "        elif metric == 'min':\n",
        "            return preds.min(axis=1)\n",
        "        elif metric == 'weighted':\n",
        "            return np.sum(preds*weight, axis=1) / np.sum(weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb6q7CZ5MFbt"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 各モデルをインスタンス化\n",
        "linreg = LinearRegression()\n",
        "svr = SVR()\n",
        "tree = DecisionTreeRegressor()\n",
        "\n",
        "models = [linreg, svr, tree]\n",
        "labels = ['Linear Regression', 'SVR', 'Decision Tree']\n",
        "\n",
        "# 各モデルのブレンドモデルをインスタンス化\n",
        "blend = Blending(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VW2mYfwMChH",
        "outputId": "c1961f69-a275-4c32-f869-927f07aae121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# 特徴量を標準化\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# 目的変数を対数変換\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_test_log = np.log1p(y_test)\n",
        "\n",
        "# 各単一モデルの学習・推定\n",
        "for model, label in zip(models, labels):\n",
        "    model.fit(X_train_std, y_train_log)\n",
        "    pred = model.predict(X_test_std)\n",
        "    print(\"{} MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# ブレンドモデルの学習・推定\n",
        "metrics = ['mean', 'median', 'max', 'min']\n",
        "\n",
        "for metric in metrics:\n",
        "    blend.fit(X_train_std, y_train_log)\n",
        "    pred = blend.predict(X_test_std, metric=metric)\n",
        "    print(\"Blended {} model MSE: {:.4f}\".format(metric, mean_squared_error(y_test_log, pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression MSE: 0.0513\n",
            "SVR MSE: 0.0454\n",
            "Decision Tree MSE: 0.0865\n",
            "\n",
            "\n",
            "Blended mean model MSE: 0.0449\n",
            "Blended median model MSE: 0.0399\n",
            "Blended max model MSE: 0.0661\n",
            "Blended min model MSE: 0.0734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbwfVB2FL2G",
        "outputId": "5363f02e-311a-49b3-9636-dada55a01314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# DataFrameをndarrayに変換\n",
        "X = np.array(train.iloc[:, :-1])\n",
        "y = np.array(train.iloc[:, -1])\n",
        "\n",
        "# データの分割（今回は8：2の割合）\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1168, 2)\n",
            "(1168,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVMS4MEOFFrv"
      },
      "source": [
        "# 交差検証用関数を作成\n",
        "def cross_validate(model, X, y, split_size=5):\n",
        "    results = []\n",
        "    kf = KFold(n_splits=split_size)\n",
        "    \n",
        "    for train_id, val_id in kf.split(X, y):\n",
        "        train_X = X[train_id]\n",
        "        train_y = y[train_id]\n",
        "        val_X = X[val_id]\n",
        "        val_y = y[val_id]\n",
        "\n",
        "        # 学習、推定\n",
        "        model.fit(train_X, train_y)\n",
        "        pred = model.predict(val_X)\n",
        "        \n",
        "        results.append(mean_squared_error(val_y, pred))\n",
        "    return np.array(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Y0UnRkEji9"
      },
      "source": [
        "# Baggingクラスの実装\n",
        "\n",
        "import copy\n",
        "\n",
        "class Bagger():\n",
        "    def __init__(self, model, n_samples, n_bootstraps=10):\n",
        "        self.model = model\n",
        "        self.n_bootstraps = n_bootstraps\n",
        "        self.n_samples = n_samples\n",
        "        self.model_list = [copy.deepcopy(model) for _ in range(n_bootstraps)]  # Shallow Copyだと変数のみCopyされるため、Deepcopyでデータ毎複製\n",
        "    \n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        for i in range(self.n_bootstraps):\n",
        "            \n",
        "            bag_id = random.randint(len(X), size=self.n_samples)\n",
        "            \n",
        "            self.model_list[i].fit(X[bag_id], y[bag_id])\n",
        "\n",
        "\n",
        "    def predict(self, X, metric='mean'):\n",
        "        \n",
        "        preds = np.empty((len(X), len(self.model_list)))\n",
        "        \n",
        "        for i, model in enumerate(self.model_list):\n",
        "            preds[:, i] = model.predict(X)\n",
        "        \n",
        "        if metric == 'mean':\n",
        "            return preds.mean(axis=1)\n",
        "        elif metric == 'median':\n",
        "            return np.median(preds, axis=1)\n",
        "        elif metric == 'max':\n",
        "            return preds.max(axis=1)\n",
        "        elif metric == 'min':\n",
        "            return preds.min(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5b1tYEeEpSP",
        "outputId": "3ac7a912-174a-48d3-907a-235e4c42bc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# 各モデルをインスタンス化\n",
        "linreg = LinearRegression()\n",
        "svr = SVR()\n",
        "tree = DecisionTreeRegressor()\n",
        "\n",
        "models = [linreg, svr, tree]\n",
        "labels = ['Linear Regression', 'SVR', 'Decision Tree']\n",
        "\n",
        "results_standalone = pd.DataFrame(index=[labels], columns=['train score', 'test score'])\n",
        "results_bagging = pd.DataFrame(index=[labels], columns=['train score', 'test score'])\n",
        "\n",
        "\n",
        "# 各単一モデルの学習・推定\n",
        "for model, label in zip(models, labels):\n",
        "    \n",
        "    # 5分割交差検証\n",
        "    results_standalone['train score'][label] = cross_validate(model, X_train_std, y_train_log).mean()\n",
        "\n",
        "    # テストデータ検証\n",
        "    model.fit(X_train_std, y_train_log)\n",
        "    pred = model.predict(X_test_std)\n",
        "    results_standalone['test score'][label] = mean_squared_error(y_test_log, pred)\n",
        "    \n",
        "#     print(\"{} MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# Baggingモデルの学習・推定\n",
        "\n",
        "for model, label in zip(models, labels):\n",
        "        \n",
        "    bagging = Bagger(model, n_samples=500, n_bootstraps=10)\n",
        "    \n",
        "    # 5分割交差検証\n",
        "    results_bagging['train score'][label] = cross_validate(bagging, X_train_std, y_train_log).mean()\n",
        "\n",
        "    bagging.fit(X_train_std, y_train_log)\n",
        "    pred = bagging.predict(X_test_std)\n",
        "    results_bagging['test score'][label] = mean_squared_error(y_test_log, pred)\n",
        "\n",
        "\n",
        "#     print(\"Bagged {} Train MSE: {:.4f}\".format(label, cross_validate(bagging, X_train_std, y_train_log).mean()))\n",
        "#     print(\"Bagged {} Test MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
        "\n",
        "print(\"単一モデルの交差検証＆推定結果\")\n",
        "print(results_standalone)\n",
        "print('\\n')\n",
        "print(\"バギングモデルの交差検証＆推定結果\")\n",
        "print(results_bagging)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "単一モデルの交差検証＆推定結果\n",
            "                  train score test score\n",
            "Linear Regression   0.0485434  0.0512843\n",
            "SVR                  0.042024  0.0453771\n",
            "Decision Tree       0.0764026  0.0874866\n",
            "\n",
            "\n",
            "バギングモデルの交差検証＆推定結果\n",
            "                  train score test score\n",
            "Linear Regression    0.048783  0.0513998\n",
            "SVR                 0.0419724  0.0499888\n",
            "Decision Tree       0.0436182   0.048793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt1FuwhOFzct"
      },
      "source": [
        "## 【問題3】スタッキングのスクラッチ実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6FN55aQFyBK"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "class Stacked():\n",
        "    def __init__(self, base_models, final_model, k=3):\n",
        "        self.base_models = base_models\n",
        "        self.final_model = final_model\n",
        "        self.k = k\n",
        "        self.model_inst = [[copy.deepcopy(self.base_models[i]) for _ in range(k)] for i in range(len(self.base_models))]\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        kfold = KFold(n_splits=self.k, shuffle=True)\n",
        "        \n",
        "        X_train_f = np.empty((len(X), len(self.base_models)))\n",
        "        \n",
        "        for i in range(len(self.model_inst)):\n",
        "            for model, (train_id, test_id) in zip(self.model_inst[i], kfold.split(X)):\n",
        "            \n",
        "                X_train, y_train = X[train_id], y[train_id]\n",
        "                X_test, y_test = X[test_id], y[test_id]\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                X_train_f[test_id, i] = model.predict(X_test)\n",
        "        \n",
        "        self.final_model.fit(X_train_f, y)\n",
        "        \n",
        "    \n",
        "    def predict(self, X):\n",
        "        X_test_f = np.empty((len(X), len(self.base_models)))\n",
        "        \n",
        "        for i in range(len(self.model_inst)):\n",
        "            \n",
        "            pred = np.empty((len(X), self.k))\n",
        "            \n",
        "            for j, model in enumerate(self.model_inst[i]):\n",
        "                pred[:, j] = model.predict(X)\n",
        "                \n",
        "            X_test_f[:, i] = pred.mean(axis=1)\n",
        "            \n",
        "        return self.final_model.predict(X_test_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeUZlautF3zj",
        "outputId": "ffe43623-0396-4f75-d819-aa9cdcd16ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "linreg = LinearRegression()\n",
        "svr = SVR()\n",
        "tree = DecisionTreeRegressor(max_depth=10)\n",
        "\n",
        "stacked = Stacked([tree, svr], linreg, k=10)\n",
        "\n",
        "models = [linreg, svr, tree, stacked]\n",
        "labels = ['Linear Regression', 'SVR', 'Decision Tree', 'Stacked']\n",
        "\n",
        "results_stacked = pd.DataFrame(index=[labels], columns=['train score', 'test score'])\n",
        "\n",
        "for model, label in zip(models, labels):\n",
        "   # 5分割交差検証\n",
        "    results_stacked['train score'][label] = cross_validate(model, X_train_std, y_train_log).mean()\n",
        "\n",
        "    # テストデータ検証\n",
        "    model.fit(X_train_std, y_train_log)\n",
        "    pred = model.predict(X_test_std)\n",
        "    results_stacked['test score'][label] = mean_squared_error(y_test_log, pred)\n",
        "    \n",
        "print(\"スタッキングモデルの交差検証＆推定結果\")\n",
        "print(results_stacked)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "スタッキングモデルの交差検証＆推定結果\n",
            "                  train score test score\n",
            "Linear Regression   0.0485434  0.0512843\n",
            "SVR                  0.042024  0.0453771\n",
            "Decision Tree        0.064919  0.0750215\n",
            "Stacked             0.0408428  0.0435241\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}