{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sprint_12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiguozhe01/DIC_Assignment/blob/master/Sprint_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh7QRfYhuuRq"
      },
      "source": [
        "## 【問題1】2次元畳み込み層の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvWrDZrvuxUq"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import linalg"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoOgg-UFuzpz"
      },
      "source": [
        "# 1フィルタ分の出力を計算\n",
        "def convolve(X, k):\n",
        "    # テプリッツ用wを生成\n",
        "    pad_h = int(X.shape[-2] - k.shape[-2])  # kの高さをXに合わせる\n",
        "    pad_w = int(X.shape[-1] - k.shape[-1])  # kの幅をXに合わせる\n",
        "    k_pad = np.pad(k, [(0,0), (0,0), (0, pad_h), (0, pad_w)])  # k(F,C,H,W)\n",
        "\n",
        "    # 次元削減\n",
        "    X_flat = np.transpose(X, (0, 2, 1, 3)).reshape(len(X), -1)  # X(N,C,H,W) → X(N,HCW)\n",
        "    k_flat = np.transpose(k_pad, (0, 2, 1, 3)).flatten()  # k(F,C,H,W) → k(FHCW)\n",
        "\n",
        "    # テプリッツ行列用の引数を準備\n",
        "    H, W = X.shape[-2:]\n",
        "    Hf, Wf = k.shape[-2:]\n",
        "    Ho, Wo = output_size((H,W), (Hf,Wf))  # 出力サイズを計算\n",
        "    # 不要な要素行を指定する\n",
        "    idx = np.arange(H * W).reshape(H, W)\n",
        "    del_row = idx[..., :H-Hf, W-Wf+1:].flatten()\n",
        "    # テプリッツの１列目\n",
        "    first_col = np.r_[k_flat[0], np.zeros(Ho*Wo + len(del_row) - 1)]  \n",
        "    # テプリッツの１行目\n",
        "    first_row = k_flat  \n",
        "\n",
        "    # テプリッツ行列を生成（不要行は削除）\n",
        "    toep = np.delete(linalg.toeplitz(first_col, first_row), del_row, axis=0)  # toep(HoWo,FHCW)\n",
        "    \n",
        "    # フィルタ毎に行列をブロック化し、縦に再結合\n",
        "    toep_reorder = np.vstack(np.split(toep, len(k), axis=1))  #toep(FHoWo,HCW)\n",
        "\n",
        "    # 行列演算\n",
        "    output = toep_reorder@X_flat.T  # out(FHoWo,N)\n",
        "\n",
        "    return output.T.reshape(len(X), len(k), Ho, Wo)  # out(N,F,Ho,Wo)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxhCsWRguqCF"
      },
      "source": [
        "class Conv2d:\n",
        "    \"\"\"\n",
        "    2D Convolution結合\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filter_size : int\n",
        "      フィルタのサイズ\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    A_ : 次の形のndarray, shape (N, F, Ho, Wo)\n",
        "      畳み込み出力\n",
        "    dZ_ : 次の形のndarray, shape (N, C, H, W)\n",
        "      逆伝播入力に対するdZ勾配\n",
        "    dw_ : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "      逆伝播入力に対するdw勾配\n",
        "    db_ : 次の形のndarray, shape (F)\n",
        "      逆伝播入力に対するdb勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (N, C, H, W)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "          ある層の重み\n",
        "        b : 次の形のndarray, shape (F)\n",
        "          ある層のバイアス\n",
        "        \"\"\"\n",
        "        \n",
        "        self.A_ = self._convolve(Z, w) + b.reshape(1, len(b), 1, 1)  # A(N,F,Ho,Wo)\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (N, C, H, W)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "          ある層の重み\n",
        "        dA : 次の形のndarray, shape (N, F, Ho, Wo)\n",
        "          ある層に逆伝播されたAに関するLoss勾配\n",
        "        \"\"\"        \n",
        "        \n",
        "        # dZ計算\n",
        "        # チャンネル毎に演算を行うため、行列を転置（NとCを残す）\n",
        "        w_ = np.transpose(w, (1,0,2,3))  # w(F,C,Hf,Wf) → w(C,F,Hf,Wf)\n",
        "        w_ = np.flip(w_)  # 上下左右に反転\n",
        "        # dAをpadding処理\n",
        "        pad_h = len(w[-2]) - 1\n",
        "        pad_w = len(w[-1]) - 1\n",
        "        dA_ = np.pad(dA, [(0,0), (0,0), (pad_h, pad_h), (pad_w, pad_w)])  # HoWo次元のみpadding\n",
        "        self.dZ_ = self._convolve(dA_, w_)  # dZ(N,C,H,W)\n",
        "        \n",
        "        \n",
        "        # dw計算            \n",
        "        # フィルタ毎に演算を行うため、行列を転置（FとCを残す）\n",
        "        Z_ = np.transpose(Z, (1,0,2,3))  # Z(N,C,H,W) → Z(C,N,H,W)\n",
        "        dA_ = np.transpose(dA, (1,0,2,3))  # dA(N,F,Ho,Wo) → dA(F,N,Ho,Wo)\n",
        "        self.dw_ = np.transpose(self._convolve(Z_, dA_), (1,0,2,3))  # dw(C,F,Hf,Wf) → dw(F,C,Hf,Wf)\n",
        "        \n",
        "        \n",
        "        # db計算 \n",
        "        # F以外の次元の和をとる\n",
        "        self.db_ = np.sum(dA, axis=(0,2,3))  # db(F)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "    \n",
        "    \n",
        "    def _output_size(self, HW, HfWf, P=0, S=1):\n",
        "    \n",
        "        HoWo = (np.array(HW) + 2*P - np.array(HfWf)) / S + 1\n",
        "        \n",
        "        return HoWo.astype('int')\n",
        "    \n",
        "    def _convolve(self, X, k):\n",
        "        \"\"\"\n",
        "        巡回演算\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (N, C, H, W)\n",
        "          巡回される行列\n",
        "        k : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "          巡回する行列\n",
        "        \"\"\"\n",
        "        # テプリッツ用wを生成\n",
        "        pad_h = int(X.shape[-2] - k.shape[-2])  # kの高さをXに合わせる\n",
        "        pad_w = int(X.shape[-1] - k.shape[-1])  # kの幅をXに合わせる\n",
        "        k_pad = np.pad(k, [(0,0), (0,0), (0, pad_h), (0, pad_w)])  # k(F,C,H,W)\n",
        "\n",
        "        # 次元削減\n",
        "        X_flat = np.transpose(X, (0, 2, 1, 3)).reshape(len(X), -1)  # X(N,C,H,W) → X(N,HCW) --[1]\n",
        "        k_flat = np.transpose(k_pad, (0, 2, 1, 3)).flatten()  # k(F,C,H,W) → k(FHCW)\n",
        "\n",
        "        # テプリッツ行列用の引数を準備\n",
        "        Ho, Wo = output_size(X.shape[-2:], k.shape[-2:])  # 出力サイズを計算\n",
        "        # 不要な要素行を指定する\n",
        "        i = k.shape[-1] - 1\n",
        "        j = X.shape[-2] - k.shape[-2]\n",
        "        del_row = []\n",
        "        for i in range(i):\n",
        "            del_row.extend(np.arange(i+j+1, X.shape[-2]*j+i+1, X.shape[-2]).astype(list)) \n",
        "        # テプリッツの１列目\n",
        "        first_col = np.r_[k_flat[0], np.zeros(Ho*Wo + len(del_row) - 1)]  \n",
        "        # テプリッツの１行目\n",
        "        first_row = k_flat  \n",
        "\n",
        "        # テプリッツ行列を生成（不要行は削除）\n",
        "        toep = np.delete(linalg.toeplitz(first_col, first_row), del_row, axis=0)  # toep(HoWo,FHCW)\n",
        "\n",
        "        # フィルタ毎に行列をブロック化し、縦に再結合\n",
        "        toep_reorder = np.vstack(np.split(toep, len(k), axis=1))  #toep(FHoWo,HCW) --[2]\n",
        "\n",
        "        # 行列演算（[2]*[1].T）\n",
        "        output = toep_reorder@X_flat.T  # out(FHoWo,N)\n",
        "\n",
        "        return output.T.reshape(len(X), len(k), Ho, Wo)  # out(N,F,Ho,Wo)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHGUCZqu4yb"
      },
      "source": [
        "## 【問題2】2次元畳み込み後の出力サイズ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR0WSsEiu4kQ"
      },
      "source": [
        "def output_size(HW, HfWf, P=0, S=1):\n",
        "    \n",
        "    # 引数を全てndarrayに変換\n",
        "    HW = np.array(HW); HfWf = np.array(HfWf); P = np.array(P); S = np.array(S)\n",
        "    \n",
        "    # ブロードキャストでHo,Woを算出\n",
        "    HoWo = (HW + 2*P - HfWf) / S + 1\n",
        "\n",
        "    return HoWo.astype('int')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV_gkKJju-0F",
        "outputId": "d19305bf-bf24-419b-eb79-bad4e6729310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_size((5,5), (3,3))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVBXmIuEvBHJ"
      },
      "source": [
        "class MaxPool2d:\n",
        "    def __init__(self, fsize):\n",
        "        self.fsize = fsize\n",
        "        self.X_shape = None\n",
        "        self.rot_shape = None\n",
        "        self.screen = None\n",
        "        self.mask = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \n",
        "        self.X_shape = X.shape\n",
        "        \n",
        "        H, W = X.shape[-2:]\n",
        "        Hf, Wf = self.fsize\n",
        "        \n",
        "            \n",
        "        Ho = H // Hf\n",
        "        Wo = W // Wf\n",
        "\n",
        "        X_pad = X[..., :Ho*Hf, :Wo*Wf]\n",
        "\n",
        "        self.screen = X.shape[:-2] + (Ho, Hf, Wo, Wf)  # 6次元\n",
        "#         pool = np.nanmax(X_pad.reshape(self.screen), axis=(-1,-3))  # Max値取得のためだけなら早い\n",
        "        \n",
        "        # 配列をフィルタ毎に再配置し（上下反転後、90度転回）、２次元に落とす\n",
        "        X_rot = np.flip(np.rot90(X_pad.reshape(self.screen), axes=(3,4)), axis=3)\n",
        "        X_2d = X_rot.reshape(-1, Hf*Wf)\n",
        "        self.rot_shape = X_rot.shape  # 逆伝播用にshapeを保存\n",
        "        \n",
        "        pool = np.nanmax(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
        "        \n",
        "        # 逆伝播用Mask行列を用意\n",
        "        self.mask = (X_2d == pool.reshape(-1,1))\n",
        "\n",
        "        return pool, X_2d, X_rot\n",
        "        \n",
        "    def backward(self, dX):\n",
        "\n",
        "        # 配列をMaskと同じ２次元に落とす\n",
        "        dpool = np.where(self.mask, dX.reshape(-1,1), 0)  # mask適用\n",
        "\n",
        "        # 元の形に戻す\n",
        "        dpool = np.rot90(np.flip(dpool.reshape(self.rot_shape), axis=3), k=3, axes=(3,4))\n",
        "        \n",
        "        return dpool.reshape(self.X_shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zdRDmhHvDcZ"
      },
      "source": [
        "## 【問題4】（アドバンス課題）平均プーリングの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxIczEWKvE9R"
      },
      "source": [
        "class MeanPool2d:\n",
        "\n",
        "    def __init__(self, fsize):\n",
        "        self.fsize = fsize\n",
        "        self.X_shape = None\n",
        "        self.rot_shape = None\n",
        "        self.screen = None\n",
        "        self.mask = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \n",
        "        self.X_shape = X.shape\n",
        "        \n",
        "        H, W = X.shape[-2:]\n",
        "        Hf, Wf = self.fsize\n",
        "        \n",
        "            \n",
        "        Ho = H // Hf\n",
        "        Wo = W // Wf\n",
        "\n",
        "        X_pad = X[..., :Ho*Hf, :Wo*Wf]\n",
        "\n",
        "        self.screen = X.shape[:-2] + (Ho, Hf, Wo, Wf)  # 6次元\n",
        "        \n",
        "        # 配列をフィルタ毎に再配置し（上下反転後、90度転回）、２次元に落とす\n",
        "        X_rot = np.flip(np.rot90(X_pad.reshape(self.screen), axes=(3,4)), axis=3)\n",
        "        X_2d = X_rot.reshape(-1, Hf*Wf)\n",
        "        self.rot_shape = X_rot.shape  # 逆伝播用にshapeを保存\n",
        "        \n",
        "        pool = np.nanmean(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
        "        \n",
        "        # 逆伝播用Mask行列を用意\n",
        "        self.mask = np.zeros(X_2d.shape)\n",
        "\n",
        "        return pool\n",
        "        \n",
        "    def backward(self, dX):\n",
        "\n",
        "        # 配列をMaskと同じ２次元に落とす\n",
        "        dpool = dX.reshape(-1,1) + self.mask  # 平均値を各poolに振り分ける\n",
        "\n",
        "        # 元の形に戻す\n",
        "        dpool = np.rot90(np.flip(dpool.reshape(self.rot_shape), axis=3), k=3, axes=(3,4))\n",
        "        \n",
        "        return dpool.reshape(self.X_shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vayrwr-kvJIn"
      },
      "source": [
        "## 【問題5】平滑化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEzGcyH1vIIe"
      },
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.shape = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \n",
        "        self.shape = X.shape\n",
        "        \n",
        "        return X.reshape(self.shape[0], np.prod(self.shape[1:]))  # X(N,C,H,W) → X(N,CHW)\n",
        "    \n",
        "    def backward(self, dX):\n",
        "        \n",
        "        return dX.reshape(self.shape)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNw7FyVNvNL-"
      },
      "source": [
        "【問題6】学習と推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWXKaje7vMFY"
      },
      "source": [
        "import time\n",
        "\n",
        "class SGD:\n",
        "    \"\"\"\n",
        "    確率的勾配降下法\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def update_dw(self, layer, grad):\n",
        "        \"\"\"\n",
        "        ある層の重み勾配を渡す\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        layer: object instance\n",
        "          ある層のインスタンス\n",
        "        grad : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          重みの勾配\n",
        "        \"\"\"\n",
        "        return grad / layer.input.shape[0]\n",
        "    \n",
        "    def update_db(self, layer, grad):\n",
        "        \"\"\"\n",
        "        ある層のバイアス勾配を渡す\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        layer: object instance\n",
        "          ある層のインスタンス\n",
        "        grad : 次の形のndarray, shape (n_nodes_self, )\n",
        "          バイアスの勾配\n",
        "        \"\"\"\n",
        "        return grad / layer.input.shape[0]\n",
        "        \n",
        "\n",
        "class AdaGrad:\n",
        "    \"\"\"\n",
        "    AdaGradによる確率的勾配降下法\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Hw : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "      ある層のイテレーション毎の重み勾配の二乗和\n",
        "    Hb : 次の形のndarray, shape (n_nodes_self, )\n",
        "      ある層のイテレーション毎のバイアス勾配の二乗和\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Hw = 1e-8\n",
        "        self.Hb = 1e-8\n",
        "        \n",
        "    def update_dw(self, layer, grad):\n",
        "        \"\"\"\n",
        "        ある層の重み勾配を渡す\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        layer: object instance\n",
        "          ある層のインスタンス\n",
        "        grad : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          重みの勾配\n",
        "        \"\"\"\n",
        "        self.Hw += (grad/layer.input.shape[0])**2\n",
        "        grad *= (1/np.sqrt(self.Hw)) / layer.input.shape[0]\n",
        "        \n",
        "        return grad\n",
        "    \n",
        "    def update_db(self, layer, grad):\n",
        "        \"\"\"\n",
        "        ある層のバイアス勾配を渡す\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        layer: object instance\n",
        "          ある層のインスタンス\n",
        "        grad : 次の形のndarray, shape (n_nodes_self, )\n",
        "          バイアスの勾配\n",
        "        \"\"\"\n",
        "        self.Hb += (grad/layer.input.shape[0])**2\n",
        "        grad *= (1/np.sqrt(self.Hb)) / layer.input.shape[0]\n",
        "        \n",
        "        return grad\n",
        "        \n",
        "        \n",
        "class Conv2d:\n",
        "    \"\"\"\n",
        "    2D Convolution結合\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filter_size : int\n",
        "      フィルタのサイズ\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    A_ : 次の形のndarray, shape (N, F, Ho, Wo)\n",
        "      畳み込み出力\n",
        "    dZ_ : 次の形のndarray, shape (N, C, H, W)\n",
        "      逆伝播入力に対するdZ勾配\n",
        "    dw_ : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "      逆伝播入力に対するdw勾配\n",
        "    db_ : 次の形のndarray, shape (F)\n",
        "      逆伝播入力に対するdb勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (N, C, H, W)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "          ある層の重み\n",
        "        b : 次の形のndarray, shape (F)\n",
        "          ある層のバイアス\n",
        "        \"\"\"\n",
        "        \n",
        "        self.A_ = self._convolve(Z, w) + b.reshape(1, len(b), 1, 1)  # A(N,F,Ho,Wo)\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (N, C, H, W)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "          ある層の重み\n",
        "        dA : 次の形のndarray, shape (N, F, Ho, Wo)\n",
        "          ある層に逆伝播されたAに関するLoss勾配\n",
        "        \"\"\"        \n",
        "        \n",
        "        # dZ計算\n",
        "        # チャンネル毎に演算を行うため、行列を転置（NとCを残す）\n",
        "        w_ = np.transpose(w, (1,0,2,3))  # w(F,C,Hf,Wf) → w(C,F,Hf,Wf)\n",
        "        w_ = np.flip(w_)  # 上下左右に反転\n",
        "        # dAをpadding処理\n",
        "        pad_h = w.shape[-2] - 1\n",
        "        pad_w = w.shape[-1] - 1\n",
        "        dA_ = np.pad(dA, [(0,0), (0,0), (pad_h, pad_h), (pad_w, pad_w)])  # HoWo次元のみpadding\n",
        "        self.dZ_ = self._convolve(dA_, w_)  # dZ(N,C,H,W)\n",
        "        \n",
        "        \n",
        "        # dw計算            \n",
        "        # フィルタ毎に演算を行うため、行列を転置（FとCを残す）\n",
        "        Z_ = np.transpose(Z, (1,0,2,3))  # Z(N,C,H,W) → Z(C,N,H,W)\n",
        "        dA_ = np.transpose(dA, (1,0,2,3))  # dA(N,F,Ho,Hw) → dA(F,N,Ho,Wo)\n",
        "        self.dw_ = np.transpose(self._convolve(Z_, dA_), (1,0,2,3))  # dw(C,F,Hf,Wf) → dw(F,C,Hf,Wf)\n",
        "\n",
        "        \n",
        "        # db計算 \n",
        "        # F以外の次元の和をとる\n",
        "        self.db_ = np.sum(dA, axis=(0,2,3))  # db(F)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "    \n",
        "    \n",
        "    def _output_size(self, HW, HfWf, P=0, S=1):\n",
        "    \n",
        "        # 引数を全てndarrayに変換\n",
        "        HW = np.array(HW); HfWf = np.array(HfWf); P = np.array(P); S = np.array(S)\n",
        "\n",
        "        # ブロードキャストでHo,Woを算出\n",
        "        HoWo = (HW + 2*P - HfWf) / S + 1   \n",
        "        \n",
        "        return HoWo.astype('int')\n",
        "    \n",
        "    \n",
        "    def _convolve(self, X, k):\n",
        "        \"\"\"\n",
        "        巡回演算\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (N, C, H, W)\n",
        "          巡回される行列\n",
        "        k : 次の形のndarray, shape (F, C, Hf, Wf)\n",
        "          巡回する行列\n",
        "        \"\"\"\n",
        "        H, W = X.shape[-2:]\n",
        "        Hf, Wf = k.shape[-2:]\n",
        "        Ho, Wo = output_size((H,W), (Hf,Wf)) \n",
        "        \n",
        "        # テプリッツ用wを生成\n",
        "        pad_h = int(H - Hf)  # kの高さをXに合わせる\n",
        "        pad_w = int(W - Wf)  # kの幅をXに合わせる\n",
        "        k_pad = np.pad(k, [(0,0), (0,0), (0, pad_h), (0, pad_w)])  # k(F,C,H,W)\n",
        "\n",
        "        # 次元削減\n",
        "        X_flat = np.transpose(X, (0, 2, 1, 3)).reshape(len(X), -1)  # X(N,C,H,W) → X(N,HCW)\n",
        "        k_flat = np.transpose(k_pad, (0, 2, 1, 3)).flatten()  # k(F,C,H,W) → k(FHCW)\n",
        "\n",
        "        # テプリッツ行列用の引数を準備\n",
        "        idx = np.arange(H * W).reshape(H, W)  # feature mapと同サイズのインデックス配列を生成\n",
        "        del_row = idx[..., :H-Hf, W-Wf+1:].flatten()  # 不要な要素行を指定する\n",
        "        first_col = np.r_[k_flat[0], np.zeros(Ho*Wo + len(del_row) - 1)]  # テプリッツの１列目\n",
        "        first_row = k_flat  # テプリッツの１行目  \n",
        "\n",
        "        # テプリッツ行列を生成（不要行は削除）\n",
        "        toep = np.delete(linalg.toeplitz(first_col, first_row), del_row, axis=0)  # toep(HoWo,FHCW)\n",
        "\n",
        "        # フィルタ毎に行列をブロック化し、縦に再結合\n",
        "        toep_reorder = np.vstack(np.split(toep, len(k), axis=1))  #toep(FHoWo,HCW)\n",
        "\n",
        "        # 行列演算\n",
        "        output = toep_reorder@X_flat.T  # out(FHoWo,N)\n",
        "\n",
        "        return output.T.reshape(len(X), len(k), Ho, Wo)  # out(N,F,Ho,Wo)\n",
        "\n",
        "        \n",
        "class Affine:\n",
        "    \"\"\"\n",
        "    線形結合\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dZ_ : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "      逆伝播入力に対するdZ勾配\n",
        "    dw_ : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "      逆伝播入力に対するdw勾配\n",
        "    db_ : 次の形のndarray, shape (n_nodes_self, )\n",
        "      逆伝播入力に対するdb勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        b : 次の形のndarray, shape (n_nodes_self, )\n",
        "          ある層のバイアス\n",
        "        \"\"\"\n",
        "        self.A_ = Z @ w + b\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたAに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dZ_ = dA @ w.T\n",
        "        self.dw_ = Z.T @ dA\n",
        "        self.db_ = np.sum(dA, axis=0)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "\n",
        "        \n",
        "class Sigmoid:\n",
        "    \"\"\"\n",
        "    シグモイド関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = 1 / (1+np.exp(-A))\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * ((1 - self.Z_) * self.Z_)\n",
        "    \n",
        "        return self.dA_\n",
        "        \n",
        "        \n",
        "class Tanh:\n",
        "    \"\"\"\n",
        "    ハイパーボリックタンジェント関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = np.tanh(A)\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * (1 - self.Z_**2)\n",
        "        \n",
        "        return self.dA_\n",
        "        \n",
        "        \n",
        "class ReLu:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        ReLu関数\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          順伝播の出力\n",
        "        dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          逆伝播入力に対するdA勾配\n",
        "        \"\"\"\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = np.maximum(A, 0)\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * np.where(self.Z_ > 0, 1, 0)\n",
        "        \n",
        "        return self.dA_\n",
        "    \n",
        "        \n",
        "class Pool2d:\n",
        " \n",
        "    def __init__(self, fsize, alg='MAX'):\n",
        "        self.fsize = fsize\n",
        "        self.alg = alg\n",
        "        self.X_shape = None\n",
        "        self.rot_shape = None\n",
        "        self.screen = None\n",
        "        self.mask = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \n",
        "        self.X_shape = X.shape\n",
        "        \n",
        "        H, W = X.shape[-2:]\n",
        "        Hf, Wf = self.fsize\n",
        "        \n",
        "       \n",
        "        Ho = H // Hf\n",
        "        Wo = W // Wf\n",
        "\n",
        "        X_pad = X[..., :Ho*Hf, :Wo*Wf]\n",
        "\n",
        "        self.screen = X.shape[:-2] + (Ho, Hf, Wo, Wf)  # 6次元\n",
        "#         pool = np.nanmax(X_pad.reshape(self.screen), axis=(-1,-3))  # Max値取得のためだけなら早い\n",
        "        \n",
        "        # 配列をフィルタ毎に再配置し（上下反転後、90度転回）、２次元に落とす\n",
        "        X_rot = np.flip(np.rot90(X_pad.reshape(self.screen), axes=(3,4)), axis=3)\n",
        "        X_2d = X_rot.reshape(-1, Hf*Wf)\n",
        "        self.rot_shape = X_rot.shape  # 逆伝播用にshapeを保存\n",
        "        \n",
        "        if self.alg == 'MAX':\n",
        "            pool = np.nanmax(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
        "            # 逆伝播用Mask行列を用意\n",
        "            self.mask = (X_2d == pool.reshape(-1,1))\n",
        "            \n",
        "        if self.alg == 'MEAN':\n",
        "            pool = np.nanmean(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
        "            # 逆伝播用Mask行列を用意\n",
        "            self.mask = np.zeros(X_2d.shape)\n",
        "\n",
        "        return pool\n",
        "        \n",
        "    def backward(self, dX):\n",
        "\n",
        "        # 配列をMaskと同じ２次元に落とす\n",
        "        if self.alg == 'MAX':\n",
        "            dpool = np.where(self.mask, dX.reshape(-1,1), 0)  # mask適用\n",
        "        if self.alg == 'MEAN':\n",
        "            dpool = dX.reshape(-1,1) + self.mask  # 平均値を各poolに振り分ける\n",
        "\n",
        "        # 元の形に戻す\n",
        "        dpool = np.rot90(np.flip(dpool.reshape(self.rot_shape), axis=3), k=3, axes=(3,4))\n",
        "        \n",
        "        return dpool.reshape(self.X_shape)\n",
        "    \n",
        "\n",
        "class Softmax:\n",
        "    \"\"\"\n",
        "    SoftMax関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        # オーバーフロー対策として定数を引き算する\n",
        "        C = np.max(A)\n",
        "        self.Z_ = np.exp(A - C) / np.sum(np.exp(A - C), axis=1)[:, None]\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, y):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          正解ラベルデータ\n",
        "        \"\"\"\n",
        "        self.dA_ = self.Z_ - y\n",
        "        \n",
        "        return self.dA_\n",
        "                    \n",
        "\n",
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.shape = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \n",
        "        self.shape = X.shape\n",
        "        \n",
        "        return X.reshape(self.shape[0], np.prod(self.shape[1:]))  # X(N,C,H,W) → X(N,CHW)\n",
        "    \n",
        "    def backward(self, dX):\n",
        "        \n",
        "        return dX.reshape(self.shape)\n",
        "\n",
        "        \n",
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    ガウス分布によるシンプルな初期化\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      ガウス分布の標準偏差\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, shape_self):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        shape_self : 次の形のndarray, shape (shape_self)\n",
        "          自身の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : 次の形のndarray, shape (shape_self)\n",
        "        \"\"\"\n",
        "        W = self.sigma * np.random.standard_normal(shape_self)\n",
        "        return W\n",
        "    \n",
        "    def B(self, shape_self):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        shape_self : 次の形のndarray, shape (shape_self)\n",
        "          自身の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : 次の形のndarray, shape (n_nodes_self, )\n",
        "        \"\"\"\n",
        "        B = np.random.randn(n_nodes_self)\n",
        "        return B\n",
        "    \n",
        "\n",
        "class XavierInitializer:\n",
        "    \"\"\"\n",
        "    ザビエルの初期値によるシンプルな初期化\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      ガウス分布の標準偏差\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.sigma = None\n",
        "    \n",
        "    def W(self, n_nodes_prev, shape_self):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        shape_self : 次の形のndarray, shape (shape_self)\n",
        "          自身の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : 次の形のndarray, shape (shape_self)\n",
        "        \"\"\"\n",
        "        self.sigma = 1 / np.sqrt(np.prod(n_nodes_prev))\n",
        "        \n",
        "        W = self.sigma * np.random.standard_normal(shape_self)  # tupleを引数にできるstandard_normalを使用\n",
        "        return W\n",
        "    \n",
        "    def B(self, shape_self):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        shape_self : 次の形のndarray, shape (shape_self)\n",
        "          自身の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : 次の形のndarray, shape (shape_self)\n",
        "        \"\"\"\n",
        "        B = np.random.standard_normal(shape_self)\n",
        "        return B\n",
        "    \n",
        "    \n",
        "class HeInitializer:\n",
        "    \"\"\"\n",
        "    フーの初期値によるシンプルな初期化\n",
        "    Attributes\n",
        "    ----------\n",
        "    sigma : float\n",
        "      ガウス分布の標準偏差\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.sigma = None\n",
        "        \n",
        "    def W(self, n_nodes_prev, shape_self):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        shape_self : 次の形のndarray, shape (shape_self)\n",
        "          自身の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : 次の形のndarray, shape (shape_self)\n",
        "        \"\"\"\n",
        "        self.sigma = np.sqrt(2/np.prod(n_nodes_prev))\n",
        "        \n",
        "        W = self.sigma * np.random.standard_normal(shape_self)  # tupleを引数にできるstandard_normalを使用\n",
        "        return W\n",
        "    \n",
        "    def B(self, shape_self):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        shape_self : 次の形のndarray, shape (shape_self)\n",
        "          自身の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : 次の形のndarray, shape (shape_self)\n",
        "        \"\"\"\n",
        "        B = np.random.standard_normal(shape_self)\n",
        "        return B\n",
        "    \n",
        "    \n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "    \n",
        "    \n",
        "class Layer:\n",
        "    \"\"\"\n",
        "    層の生成\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    combination : object instance\n",
        "      結合関数インスタンス\n",
        "    activation : object instance\n",
        "      活性化関数インスタンス\n",
        "    initializer : object instance\n",
        "      初期化方法のインスタンス\n",
        "    optimizer : object instance\n",
        "      最適化手法のインスタンス\n",
        "    n_nodes_prev : int\n",
        "      前の層のノード数\n",
        "    n_nodes_self : int\n",
        "      自身の層のノード数\n",
        "      \n",
        "    Attributes\n",
        "    ----------\n",
        "    w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "      重みパラメータ\n",
        "    b : 次の形のndarray, shape (n_nodes_self, )\n",
        "      バイアスパラメータ\n",
        "    input : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "      入力データ\n",
        "    output : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      出力データ\n",
        "    prev : object instance\n",
        "      前の層\n",
        "    next : object instance\n",
        "      後の層\n",
        "    \"\"\"\n",
        "    def __init__(self, combination, activation, \n",
        "                 initializer=None, optimizer=None, n_nodes_prev=None, w_shape=None, b_shape=None):\n",
        "        self.comb = combination\n",
        "        self.activ = activation\n",
        "        self.initializer = initializer # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "        self.optimizer = optimizer\n",
        "        self.n_nodes_prev = n_nodes_prev\n",
        "        self.w_shape = w_shape\n",
        "        self.b_shape = b_shape\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        self.prev = None\n",
        "        self.next = None\n",
        "        \n",
        "        if self.initializer:\n",
        "            self.w = self.initializer.W(self.n_nodes_prev, self.w_shape)\n",
        "            self.b = self.initializer.B(self.b_shape)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "            入力\n",
        "            \n",
        "        Returns\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "            出力\n",
        "        \"\"\"        \n",
        "        if self.comb:\n",
        "            A = self.comb.forward(X, self.w, self.b)\n",
        "            Z = self.activ.forward(A)\n",
        "\n",
        "        else:\n",
        "            Z = self.activ.forward(X)\n",
        "        \n",
        "        self.input = X\n",
        "        self.output = Z\n",
        "        \n",
        "        if self.next:\n",
        "            return self.next.forward(Z)\n",
        "        else:\n",
        "            return Z\n",
        "    \n",
        "    def backward(self, y, lr):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "            後ろから流れてきた勾配\n",
        "        lr : float\n",
        "          学習率\n",
        "        \"\"\"\n",
        "        if self.comb:\n",
        "            dA = self.activ.backward(y)\n",
        "            dZ, dw, db = self.comb.backward(self.input, self.w, dA)\n",
        "            \n",
        "            # パラメータ更新\n",
        "            self.w -= lr * self.optimizer.update_dw(self, dw)\n",
        "            self.b -= lr * self.optimizer.update_db(self, db)\n",
        "            \n",
        "        else:\n",
        "            dZ = self.activ.backward(y)\n",
        "\n",
        "        \n",
        "        if self.prev:\n",
        "            self.prev.backward(dZ, lr)\n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    \n",
        "class ScratchConvNeuralNetworkClassifier:\n",
        "    \"\"\"\n",
        "    可変層畳み込みニューラルネットワーク分類器\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    layers : list\n",
        "      ネットワークに組み込まれる層のリスト\n",
        "    epoch : int\n",
        "      エポック数\n",
        "    sigma : float\n",
        "      初期パラメータ用（SimpleInitializerのみ適用）\n",
        "    batch_size : int\n",
        "      ミニバッチのサンプル数\n",
        "    verbose : bool\n",
        "      学習経過の出力\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    loss_train : list\n",
        "      訓練データに対するLoss\n",
        "    loss_val : list\n",
        "      検証データに対するLoss\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, epoch=100, sigma=0.1, lr=0.01, batch_size=100, verbose=False, **kwargs):\n",
        "        self.layers = layers\n",
        "        self.epoch = epoch\n",
        "        self.lr = lr\n",
        "        self.sigma = sigma\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "\n",
        "        # レイヤー同士を結合\n",
        "        for i, layer in enumerate(layers): \n",
        "            if i == 0:\n",
        "                layer.next = self.layers[i+1]\n",
        "            elif layer == layers[-1]:\n",
        "                layer.prev = self.layers[i-1] \n",
        "            else:\n",
        "                layer.next = self.layers[i+1]\n",
        "                layer.prev = self.layers[i-1]\n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, n_classes)\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, n_classes)\n",
        "            検証データの正解値\n",
        "        \"\"\"  \n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            \n",
        "            get_mini_batch_t = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            \n",
        "            times = []\n",
        "            start = time.time()\n",
        "            \n",
        "            # 各mini batchの損失をリスト化\n",
        "            loss_batch_t = []\n",
        "            \n",
        "            for X_mini, y_mini in get_mini_batch_t:\n",
        "\n",
        "                # 順伝播\n",
        "                output = self.layers[0].forward(X_mini)\n",
        "                # 逆伝播\n",
        "                self.layers[-1].backward(y_mini, self.lr)\n",
        "\n",
        "                loss_batch_t.append(self.cross_entropy(output, y_mini))\n",
        "            \n",
        "            # 各epochの平均損失をselfに格納\n",
        "            loss_train = np.mean(loss_batch_t)\n",
        "            self.loss_train.append(loss_train)\n",
        "            \n",
        "            \n",
        "            # 検証データの推定\n",
        "            if hasattr(X_val, '__array__') and hasattr(y_val, '__array__'):\n",
        "                \n",
        "                batch_size_v = int(self.batch_size * len(X_val)/len(X))\n",
        "                get_mini_batch_v = GetMiniBatch(X_val, y_val, batch_size=batch_size_v)\n",
        "                loss_batch_v = []\n",
        "\n",
        "                for X_mini, y_mini in get_mini_batch_v:\n",
        "                    \n",
        "                    output = self.layers[0].forward(X_mini)\n",
        "                \n",
        "                    loss_batch_v.append(self.cross_entropy(output, y_mini))\n",
        "            \n",
        "                # 各epochの平均損失をselfに格納\n",
        "                loss_val = np.mean(loss_batch_v)\n",
        "                self.loss_val.append(loss_val)\n",
        "\n",
        "            end = time.time()\n",
        "            times.append(end-start)\n",
        "\n",
        "            # 学習経過の出力\n",
        "            if self.verbose and (i+1) % 10 == 0:\n",
        "                print(\"Epoch {}; Loss {:.4f}\".format(i+1, loss_train),\n",
        "                      \"  --Avg Epoch Time {:.4f}sec\".format(np.mean(times)))            \n",
        "                   \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を使い推定する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "          検証用データ\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "          次の形のndarray, shape (n_samples, )\n",
        "          推定結果\n",
        "        \"\"\"\n",
        "        output = self.layers[0].forward(X)\n",
        "        \n",
        "        return np.argmax(output, axis=1)\n",
        "        \n",
        "    def cross_entropy(self, X, y):\n",
        "        \"\"\"\n",
        "        クロスエントロピー誤差を計算\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_features)\n",
        "          入力データ\n",
        "        y : 次の形のndarray, shape (batch_size, n_classes)\n",
        "          入力データの正解ラベル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "          float\n",
        "          クロスエントロピー誤差\n",
        "        \"\"\"\n",
        "        return (-1/len(X)) * np.sum((y*np.log(X)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3qKzqwpvX7r",
        "outputId": "27ff2883-6001-4f25-e27c-980e07247d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#《データセットをダウンロードするコード》\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Xを標準化\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "# yをone-hot encode\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "# データを分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "# 特徴量を４次元に変換\n",
        "X_train = X_train[:, None, :, :]\n",
        "X_val = X_val[:, None, :, :]\n",
        "X_test = X_test[:, None, :, :]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le9j32EyvZ3K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(model, title='Scratch CNN Loss'):\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(np.arange(len(model.loss_train)), model.loss_train, label='train loss')\n",
        "    plt.plot(np.arange(len(model.loss_val)), model.loss_val, label='val loss')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7yPjblIvcKl",
        "outputId": "58a1a67b-34ee-4c89-b41c-322d12b3221d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "# 5000サンプルで学習\n",
        "\n",
        "# ハイパーパラメータの設定 w(F,C,Hf,Wf) b(F)\n",
        "W1 = np.array((5,1,5,5)); B1 = 5\n",
        "W2 = np.array((320,10)); B2 = 10\n",
        "\n",
        "# 4層のConvネットワーク\n",
        "layer_1 = Layer(Conv2d(), ReLu(), HeInitializer(), AdaGrad(), 784, W1, B1)  # 1,28,28 to 5,24,24\n",
        "layer_2 = Layer(None, Pool2d((3,3))) # 5,24,24 to 5,8,8\n",
        "layer_3 = Layer(None, Flatten())  # 5,8,8 to 320\n",
        "output = Layer(Affine(), Softmax(), XavierInitializer(), AdaGrad(), 320, W2, B2)  # 320 to 10\n",
        "\n",
        "params = {'epoch': 100, \n",
        "          'lr': 0.01,\n",
        "          'batch_size': 200,\n",
        "          }\n",
        "\n",
        "cnn = ScratchConvNeuralNetworkClassifier(layers=[layer_1, layer_2, layer_3, output], verbose=True, **params)\n",
        "\n",
        "cnn.fit(X_train[:5000], y_train[:5000], X_val[:5000], y_val[:5000])\n",
        "\n",
        "pred = cnn.predict(X_test)\n",
        "\n",
        "print(\"\\n Accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "plot_loss(cnn)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10; Loss 0.5626   --Avg Epoch Time 12.0384sec\n",
            "Epoch 20; Loss 0.3837   --Avg Epoch Time 12.1350sec\n",
            "Epoch 30; Loss 0.3139   --Avg Epoch Time 12.0542sec\n",
            "Epoch 40; Loss 0.2765   --Avg Epoch Time 12.1549sec\n",
            "Epoch 50; Loss 0.2525   --Avg Epoch Time 12.0851sec\n",
            "Epoch 60; Loss 0.2353   --Avg Epoch Time 12.2374sec\n",
            "Epoch 70; Loss 0.2240   --Avg Epoch Time 12.2084sec\n",
            "Epoch 80; Loss 0.2137   --Avg Epoch Time 12.1575sec\n",
            "Epoch 90; Loss 0.2057   --Avg Epoch Time 11.8751sec\n",
            "Epoch 100; Loss 0.1992   --Avg Epoch Time 12.0294sec\n",
            "\n",
            " Accuracy: 0.939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwcdZ3/8den7zl6MpOLnGQCBCQHBEhiIHKou0hgRVhEQBTBVRZ/KPBTUXZ9rIo/LxSPjaKIioIHxwIiCooHR2A5JIQAgQBJICHXJDNJ5j76+v7+qOpJJ8xMJsn09MzU+/l49GO6qr9V9anpZN79/VZ1lTnnEBGR4AqVugARESktBYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBkD2ZWa2bOzCKlrkVkMCgIpKTM7B1m9oSZNZnZDjP7XzObX4TtXGxmjw/0egvWv8DMHjCzRn8//mFml/ivneIHy4/2WOZxM7u4oD5nZp/bo81GMzull23+0sy+Wpw9kiBREEjJmFkV8EfgB8BoYDJwLdC1j+sp6Sd3MzseeAh4FDgMGAN8Alhc0KwN+LCZ1faxqh3A58wsWZxKRXqmIJBSOhzAOXebcy7rnOtwzv3FOfdCvoGZfdzMVplZi5m9bGbH+vPXmdnnzewFoM3MImZ2jZmtLWh7tt/2SOBG4HgzazWzRn9+mZl9x8zW+z2Sx82srKC+C83sTTNrMLMv9LEf3wZucc5d55xrcJ5nnXMfKGjTCPwS+FIf61kFPAl8up+/v175v7c1fu/kPjOb5M83M/uemW0zs2Yze9HMZvuvne7/3lrMbJOZffZA65DhQUEgpfQakDWzW8xssZnVFL5oZucCXwYuAqqAM4HtBU0uAM4Aqp1zGWAtcCIwCq9n8Wszm+icWwVcBjzpnKt0zlX7y18PHAecgNcj+RyQK1j/O4AjgHcDX/QDZTdmVg4cD9zVj/39GnCOmR3RR5v/Aq4ys9H9WF+PzOxdwDeADwATgfXA7f7LpwIn4YXwKL9N/nf6c+DfnXNJYDZeL0cCQEEgJeOca8b7Y+uAnwL1/qfXg/wmHwO+5Zx7xv+UvcY5t75gFUuccxuccx3++v7HObfZOZdzzt0BrAYW9LRtMwsBHwWudM5t8nskTzjnCoelrvV7Kc8DzwNH97CqGrz/R1v6sb91eD2Tr/TRZgXwV+Dze1tfHy4EbnbOLff35z/wekO1QBpIAm8DzDm3yjmXrz0NzDSzKufcTufc8gOoQYYRBYGUlP+H6GLn3BS8T6GTgO/7L0/F+5Tfmw2FE2Z2kZmt8A/YNvrrG9vLsmOBxF7WX1fwvB2o7KHNTrxexMQ+1lPoOuA9ZtZTqOR9EfhEQSDuq0l4vQAAnHOteJ/6JzvnHgJ+CNwAbDOzm/xjNQDnAKcD683sUf/YhwSAgkCGDOfcK3jj6LP9WRuAQ/taJP/EzKbh9So+CYzxh39WArZnW18D0LmX9fen5na8cf1z+tl+O17Q/b8+2rwC3AP0dVyiL5uBafkJM6vAO4C9yV//EufcccBMvCGiq/35zzjn3geMB+4F7tzP7cswoyCQkjGzt5nZZ8xsij89FW/c/ym/yc+Az5rZcf5BzsP8P/g9qcD7Y1/vr+sSdgUKwFZgipnFAJxzOeBm4LtmNsnMwmZ2vJnF92NXPgdcbGZXm9kYf/tHm9ntvbT/Lt5xibcccyhwLXAJUN1HG4CwmSUKHjHgNuASM5vr78/Xgaedc+vMbL6Zvd3MonhnMnUCOTOLmdmFZjbKOZcGmtn9eImMYAoCKaUW4O3A02bWhhcAK4HPgDfmj3eA9bd+23vxDuq+hXPuZeA7eJ/OtwJzgP8taPIQ8BJQZ2YN/rzPAi8Cz+Cdunkd+/F/wjn3BPAu//G6me0AbgIe6KV9M/Ct3vbFb/MG8Cu8gOvLNUBHweMh59zf8A4634137OJQ4Hy/fRVez2kn3vDRdryzngA+DKwzs2a8g+sX7mXbMkKYbkwjIhJs6hGIiAScgkBEJOAUBCIiAacgEBEJuGF3md2xY8e62traUpchIjKsPPvssw3OuXE9vTbsgqC2tpZly5aVugwRkWHFzNb39pqGhkREAk5BICIScAoCEZGAG3bHCERk5Eqn02zcuJHOzs5SlzJsJRIJpkyZQjQa7fcyCgIRGTI2btxIMpmktrYWM9v7ArIb5xzbt29n48aNTJ8+vd/LaWhIRIaMzs5OxowZoxDYT2bGmDFj9rlHpSAQkSFFIXBg9uf3F5ggeLWuhesffJUdbalSlyIiMqQEJgjeaGjlhw+vYWuzDkKJSM8aGxv50Y9+tF/Lnn766TQ2Nva7/Ze//GWuv/76/drWQAtMEFTEvePirV2ZElciIkNVX0GQyfT9t+OBBx6gunpvN5QbmgITBJX5IOhUEIhIz6655hrWrl3L3Llzufrqq3nkkUc48cQTOfPMM5k5cyYAZ511FscddxyzZs3ipptu6l62traWhoYG1q1bx5FHHsnHP/5xZs2axamnnkpHR0ef212xYgULFy7kqKOO4uyzz2bnzp0ALFmyhJkzZ3LUUUdx/vneTeYeffRR5s6dy9y5cznmmGNoaWk54P0OzOmjyYR6BCLDybV/eImXNzcP6DpnTqriS++d1evr3/zmN1m5ciUrVqwA4JFHHmH58uWsXLmy+3TMm2++mdGjR9PR0cH8+fM555xzGDNmzG7rWb16Nbfddhs//elP+cAHPsDdd9/Nhz70oV63e9FFF/GDH/yAk08+mS9+8Ytce+21fP/73+eb3/wmb7zxBvF4vHvY6frrr+eGG25g0aJFtLa2kkgkDvTXEqQegfflCgWBiOyLBQsW7HZO/pIlSzj66KNZuHAhGzZsYPXq1W9ZZvr06cydOxeA4447jnXr1vW6/qamJhobGzn55JMB+MhHPsLSpUsBOOqoo7jwwgv59a9/TSTifZhdtGgRn/70p1myZAmNjY3d8w9EYHoEFfEwoKEhkeGir0/ug6mioqL7+SOPPMLf/vY3nnzyScrLyznllFN6PGc/Ho93Pw+Hw3sdGurN/fffz9KlS/nDH/7A1772NV588UWuueYazjjjDB544AEWLVrEgw8+yNve9rb9Wn9eYHoEFTENDYlI35LJZJ9j7k1NTdTU1FBeXs4rr7zCU089dcDbHDVqFDU1NTz22GMA/OpXv+Lkk08ml8uxYcMG3vnOd3LdddfR1NREa2sra9euZc6cOXz+859n/vz5vPLKKwdcQ2B6BKGQURmPKAhEpFdjxoxh0aJFzJ49m8WLF3PGGWfs9vppp53GjTfeyJFHHskRRxzBwoULB2S7t9xyC5dddhnt7e0ccsgh/OIXvyCbzfKhD32IpqYmnHNcccUVVFdX81//9V88/PDDhEIhZs2axeLFiw94++acG4DdGDzz5s1z+3tjmrd//W+ccvh4rnv/UQNclYgMhFWrVnHkkUeWuoxhr6ffo5k965yb11P7wAwNAeoRiIj0IFhBkIgqCERE9hCoIEiqRyAi8haBCoKKeFinj4qI7CFQQVAZ19CQiMieAhUEyYSGhkRE9hSoIMifNTTcTpkVkaGrsrJyn+YPRYEKgop4hGzO0ZnOlboUEZEhI1BBUOlfgbSlK13iSkRkKLrmmmu44YYbuqfzN49pbW3l3e9+N8ceeyxz5szh97//fb/X6Zzj6quvZvbs2cyZM4c77rgDgC1btnDSSScxd+5cZs+ezWOPPUY2m+Xiiy/ubvu9731vwPexJ4G5xASr/8pZj32Wn9qVtHVlIVnqgkSkT3+6BupeHNh1TpgDi7/Z68vnnXceV111FZdffjkAd955Jw8++CCJRILf/e53VFVV0dDQwMKFCznzzDP7dX/ge+65hxUrVvD888/T0NDA/PnzOemkk/jtb3/Le97zHr7whS+QzWZpb29nxYoVbNq0iZUrVwLs0x3PDkRwgiDTRbJtHUk6dAqpiPTomGOOYdu2bWzevJn6+npqamqYOnUq6XSa//zP/2Tp0qWEQiE2bdrE1q1bmTBhwl7X+fjjj3PBBRcQDoc56KCDOPnkk3nmmWeYP38+H/3oR0mn05x11lnMnTuXQw45hNdff51PfepTnHHGGZx66qmDsNdBCoJYOQBldGpoSGQ46OOTezGde+653HXXXdTV1XHeeecB8Jvf/Ib6+nqeffZZotEotbW1PV5+el+cdNJJLF26lPvvv5+LL76YT3/601x00UU8//zzPPjgg9x4443ceeed3HzzzQOxW30KzjGCqB8EllKPQER6dd5553H77bdz1113ce655wLe5afHjx9PNBrl4YcfZv369f1e34knnsgdd9xBNpulvr6epUuXsmDBAtavX89BBx3Exz/+cT72sY+xfPlyGhoayOVynHPOOXz1q19l+fLlxdrN3QSnR+AHQTldtKUUBCLSs1mzZtHS0sLkyZOZOHEiABdeeCHvfe97mTNnDvPmzdunG8GcffbZPPnkkxx99NGYGd/61reYMGECt9xyC9/+9reJRqNUVlZy6623smnTJi655BJyOe/Mxm984xtF2cc9Becy1A1r4IfHcVXq/3Dce/+dDx9fO+C1iciB0WWoB4YuQ92b/DEC66JF3y4WEekWnCCIlgFQqWMEIiK7CVAQeDegHhVN06YegciQNdyGq4ea/fn9FS0IzGyqmT1sZi+b2UtmdmUPbczMlpjZGjN7wcyOLVY9RGIQilAVSmtoSGSISiQSbN++XWGwn5xzbN++nUQisU/LFfOsoQzwGefccjNLAs+a2V+dcy8XtFkMzPAfbwd+7P8sjmg5SZfW0JDIEDVlyhQ2btxIfX19qUsZthKJBFOmTNmnZYoWBM65LcAW/3mLma0CJgOFQfA+4Fbnxf9TZlZtZhP9ZQdetJxkNqVLUYsMUdFolOnTp5e6jMAZlGMEZlYLHAM8vcdLk4ENBdMb/Xl7Ln+pmS0zs2UH9EkhWka5pXSMQESkQNGDwMwqgbuBq5xzzfuzDufcTc65ec65eePGjdv/YmIVVOj0URGR3RQ1CMwsihcCv3HO3dNDk03A1ILpKf684oiWUW5dOkYgIlKgmGcNGfBzYJVz7ru9NLsPuMg/e2gh0FS04wMA0XISrkvHCEREChTzrKFFwIeBF81shT/vP4GDAZxzNwIPAKcDa4B24JIi1gOxCuJspj2VJZtzhEN7v5a4iMhIV8yzhh4H+vxL658tdHmxaniLaBnxXBcAbakMVYnooG1aRGSoCs43iwGi5URz3jXEdZxARMQTuCCI5INAxwlERICgBUGsnEi2A1AQiIjkBSsIouWEcmkiZDQ0JCLiC1wQAJShy0yIiOQFKwi6b2CvL5WJiOQFKwiiu+5Sph6BiIgnkEFQjoJARCQvkEEwKpJWEIiI+IIVBP4xgtHRDC06RiAiAgQtCPwb2FdHM7ongYiIL2BB4N3AvjqqoSERkbxgBYE/NDQqnNLpoyIivmAFgX+wuCqc0V3KRER8gQyCZFj3LRYRyQtWEETigFER0iUmRETyghUEZt03sNcxAhERT7CCAPwb2KdIZXN0ZbKlrkZEpOQCGATllOHfrrJLQSAiErwgiFUQd14QaHhIRCSIQRAtI+6821W2dKVLXIyISOkFMAjKiekG9iIi3QIZBFE/CHThORGRIAZBwQ3sNTQkIhLEIIiWE86qRyAikhfIIAhl2gEFgYgIBDIIyrB0B7FwiOZODQ2JiAQvCGIVkOlkVNzUIxARIYhB4F+BdGwipyAQESGQQeDdrnJsPEuLhoZERAIYBDHvdpVjYrqBvYgIBDEI/B5BTTSjHoGICIEMAq9H4AWBegQiIgEMAq9HMCqaVhCIiBDEIIjlb2CfprUrQzbnSlyQiEhpBS8I/KGhqrB3fED3LhaRoAtgEHhDQ8mQd3MaHTAWkaArWhCY2c1mts3MVvby+ilm1mRmK/zHF4tVy27800crLAXoekMiIpEirvuXwA+BW/to85hz7l+KWMNb+T2CcgWBiAhQxB6Bc24psKNY699vES8IykxDQyIiUPpjBMeb2fNm9iczmzUoWwyFIFJGwuWDQD0CEQm2Yg4N7c1yYJpzrtXMTgfuBWb01NDMLgUuBTj44IMPfMuxcmL5G9irRyAiAVeyHoFzrtk51+o/fwCImtnYXtre5Jyb55ybN27cuAPfeLSCuN8jaFaPQEQCrmRBYGYTzMz85wv8WrYPysajZYQy7UTDuieBiEjRhobM7DbgFGCsmW0EvgREAZxzNwLvBz5hZhmgAzjfOTc4X/ONlWPpDpKJqIaGRCTwihYEzrkL9vL6D/FOLx180XJItZNMRNQjEJHAK/VZQ6URLYd0mx8E6hGISLAFNAjKIN1BMh5Vj0BEAi+YQRCr0NCQiIgvmEEQLYd0uw4Wi4gQ2CAo84NAPQIRkWAGQawC0u1UxcO0pjLkdHMaEQmwYAaBfwXS6lgW56A1pV6BiARXQIPAv4F9xDs+oOEhEQmygAZB/gb2XgA0d+iAsYgEV7+CwMwqzCzkPz/czM40s2hxSyui7hvY6+Y0IiL97REsBRJmNhn4C/BhvDuQDU/+0FAy7AWATiEVkSDrbxCYc64d+FfgR865c4HBuZFMMfj3LU5aO6AegYgEW7+DwMyOBy4E7vfnhYtT0iCoPAiAinQDoB6BiARbf4PgKuA/gN85514ys0OAh4tXVpFVTQSgvLMe0M1pRCTY+nUZaufco8CjAP5B4wbn3BXFLKyo4kmIJYm01RENH6GhIREJtP6eNfRbM6syswpgJfCymV1d3NKKLDkBa9mi6w2JSOD1d2hopnOuGTgL+BMwHe/MoeGraiK01Ol6QyISeP0Ngqj/vYGzgPucc2lgeF+gJzkRmrfo5jQiEnj9DYKfAOuACmCpmU0DmotV1KBIToSWLSRj6hGISLD1Kwicc0ucc5Odc6c7z3rgnUWurbiSEyGXZmKsTUEgIoHW34PFo8zsu2a2zH98B693MHz5p5BODjdqaEhEAq2/Q0M3Ay3AB/xHM/CLYhU1KJKTAJhgO9UjEJFA69f3CIBDnXPnFExfa2YrilHQoElOAGA8O2hNTSKXc4RCVuKiREQGX397BB1m9o78hJktAjqKU9Ig8YNgdG6Hbk4jIoHW3x7BZcCtZjbKn94JfKQ4JQ2ScBQqxlGd8S4z0dKZoSoxfK+sLSKyv/p7iYnngaPNrMqfbjazq4AXillc0SUnkkwVXniurLT1iIiUwD7docw51+x/wxjg00WoZ3AlJ1Ke2gboUtQiElwHcqvK4X9ktWoi8Y58EOgUUhEJpgMJguF9iQmA5CSinduJkmHjzuF97FtEZH/1eYzAzFro+Q++MRIG1P0zh6YnWli9tbXExYiIlEafQeCcSw5WISVR5X2p7LiaDlZvaylxMSIipXEgQ0PDn98jmFXZzppt6hGISDAFPAi8HsGhiRYaWlPsaEuVuCARkcEX7CAoHw3hGJMjjQDqFYhIIAU7CMwgOYGxbgeAjhOISCAFOwgAkpMo69xKRSysM4dEJJAUBMkJWEsdh42vZG29gkBEgkdBUDUJmrdw6LgK9QhEJJCKFgRmdrOZbTOzlb28bma2xMzWmNkLZnZssWrpU3ICpNuYOSZEXXMnzbrUhIgETDF7BL8ETuvj9cXADP9xKfDjItbSO/8U0pmVXm9AZw6JSNAULQicc0uBHX00eR9wq/M8BVSb2cRi1dMr/0tlh8a9i6qu0fCQiARMKY8RTAY2FExv9Oe9hZldambLzGxZfX39wFYxdgYA49pXE4+EdAqpiATOsDhY7Jy7yTk3zzk3b9y4cQO78uQEGH0oofVPcOi4SlZraEhEAqaUQbAJmFowPcWfN/imnQBvPsHh48t05pCIBE4pg+A+4CL/7KGFQJNzbktJKql9B3Q28faKrWxq7KCtS3crE5Hg6O/N6/eZmd0GnAKMNbONwJeAKIBz7kbgAeB0YA3QDlxSrFr2atoiAOZmXwJmsba+laOmVJesHBGRwVS0IHDOXbCX1x1webG2v0+qp0L1wUxteQ6YxStbWhQEIhIYw+Jg8aCY9g4q6p5mbEWMpasH+MwkEZEhTEGQV7sIa9/O+bVtLH2tnnQ2V+qKREQGhYIgzz9OsLhqLc2dGZ5dv7PEBYmIDA4FQV5NLVRN5vDOF4mGjYdf2VbqikREBoWCIM8Mpp1AdMMTLKit4e8KAhEJCAVBoWmLoHUrZx3cxZptrWzY0V7qikREik5BUKj2RADeGX0RgIfUKxCRAFAQFBpzKBw0m7Fr7mH62AoND4lIICgICpnB3A/C5uWcN62Vp17fTntKl5sQkZFNQbCno86DUIT35h4mlcnx+OqGUlckIlJUCoI9VYyFw09j0pv3MaYsxL0rSnNBVBGRwaIg6MncD2Jt2/jcYRv4y0tb2dbcWeqKRESKRkHQkxmnQvlY/iX3CJmc4/ZnNux9GRGRYUpB0JNwFI46j4o3/sLiQ6Lc9o83yejaQyIyQikIejP3g5BLc+XYZ9nS1MnDr+qKpCIyMikIejNhNkxbxBFv3MqUZIhfP7W+1BWJiBSFgqAvJ34Ga9nMlw5+gaWr63lzuy45ISIjj4KgL4e+CyYdwzsbfkPUcvzyiXWlrkhEZMApCPpiBid+lkjTer40/RV+8/R6tupUUhEZYRQEe3PE6TDuSM7tuJNcLssPH1pT6opERAaUgmBvQiE48TPEdrzGl2es4/Zn3tTlqUVkRFEQ9Mess2HsEZy380bKrYsfPLS61BWJiAwYBUF/hCPwL98j0ryBH0/+C3cv38Tr9a2lrkpEZEAoCPqrdhEc+xGO33Y7cyPr+MofX8Y5V+qqREQOmIJgX/zzV7CKcfxk1K089modtz6pL5mJyPCnINgXZdWw+DrGtqzimxMe4WsPrOKVuuZSVyUickAUBPtq5lkw8328v+kXvDu2iitue47OdLbUVYmI7DcFwb4yg/fdgI09giXRJbRve52v/PHlUlclIrLfFAT7I56E873LTtxdcwO/e/o1bv/Hm6WuSkRkvygI9teYQ+GcmxnfvoZbam7mi79/gWfX7yx1VSIi+0xBcCBm/BN26ldZ0PE4Xy+7jct+tUzXIhKRYUdBcKBO+CQsvJz3Z/7IB1L38rFbltHalSl1VSIi/aYgGAinfhVmnc3VoV9z2NYHuPTWZXRldCaRiAwPCoKBEArB2T+B2hP5buTHjH3jPq68bYXucywiw4KCYKBE4vDBO7DaRXw/9mMqVt3JNfe8SDany1CIyNCmIBhIsQr44J2EDjmJ62M/IbriFq647TkNE4nIkKYgGGixcrjgDmzGP/ON6M9ZsOrr/Psvn6Q9pQPIIjI0KQiKIZqA82+DEz7FRyJ/5ZNv/l8uv/EBNjd2lLoyEZG3KGoQmNlpZvaqma0xs2t6eP1iM6s3sxX+42PFrGdQhSPe2UTvv5m50Y18e/sn+fp/L+GRV7eVujIRkd0ULQjMLAzcACwGZgIXmNnMHpre4Zyb6z9+Vqx6Smb2OUT+/SGSYyfxQ/d11v3qk3z/ged1RpGIDBnF7BEsANY45153zqWA24H3FXF7Q9f4I4lf9giZ+ZdxceRBFj/1Qf7jhl/p3sciMiQUMwgmAxsKpjf68/Z0jpm9YGZ3mdnUnlZkZpea2TIzW1ZfX1+MWosvmiByxnXwobs5uDzFN7ZfxZ+WXM79y9eVujIRCbhSHyz+A1DrnDsK+CtwS0+NnHM3OefmOefmjRs3blALHHCH/RNlVz5D18xzuZR7OPze07n5hq+xuaGx1JWJSEAVMwg2AYWf8Kf487o557Y757r8yZ8BxxWxnqGjrJqK824ic/7tjEkm+Gj9t4j94CiW3/I5uloaSl2diARMMYPgGWCGmU03sxhwPnBfYQMzm1gweSawqoj1DDmRty1m9GefZdtZd7Cx/EiOfeMnpL8zhxd//XlSrbqktYgMjqIFgXMuA3wSeBDvD/ydzrmXzOwrZnam3+wKM3vJzJ4HrgAuLlY9Q5YZ4+eextGf+zPLTr+fF2LHMGfNjXRdP5OXfn4ZbRteLHWFIjLCmXPD61o48+bNc8uWLSt1GUXjnGPZ04/S+cj3WNDxOHHL8GbFHMoXXMTYBR+AsupSlygiw5CZPeucm9fjawqCoeulNa+z5i8/ZfbWeznUNpMmSuPUdzHm+A8RmnGq9w1mEZF+UBAMc9uaOvjb3x/EXryDf849zlhrpjNcSebwM6ic+68w/STvGkciIr1QEIwQXZksD76wkVVP/pFD6/7Me0LPkLQOMqE4uWknEjvyNDj8PVB9cKlLFZEhRkEwAm1u7OC+5W+wftlfmdH8BO8OP8c02wpAV83hxGa8Ezt4IRy8EKomlbhaESk1BcEI90pdM/c9t4nXXn6OaTse552hFcwLryZBCoDcqGmEahdB7SKYtghqasGstEWLyKBSEATI5sYOHnm1nsdf3cKOtcuYlXmZ+aFXOSHyKlWuGYBcciKhaYtgynw4aJb3KB9d4spFpJgUBAGVzuZ47s1GnljbwJNr6mnesJLjWMXC8KucEHmF0bkduxpXTYEpx8HkeTDpGBh3BFSMU89BZIRQEAgAHaksz6zbweNrGnjstXoa6t7kyNCbHB3dxAkVGzky+yrVXVt2LZAYBWNmwJjD/MehMHYGjD5UZymJDDMKAunRjrYUT72+nf9d08DyNxt5bWsL1blGZoXWMTu+jWMrGjgstIXx6Y2Ud9TtvnDVFKiZ5p2hVD3NC4hxb/MCQ99vEBlyFATSL53pLKu2NLNyUxMrNzXz4qYmXtvaQibnSNDF9NBWFlbt4Jjyeg4Lb2WC20ayczOR1i0Y+X9HBsmJUD0VRk31g8J/jJoKoyZDrKKk+ykSRH0FQWSwi5GhKxENc8zBNRxzcE33vHQ2x/rtbby2tZVX61p4ta6FR7a2sG57G/nPEGWhDMeP2sn8ym3MjNQxJVTP2HQ9lRv+Qejle7FcZvcNldVA1WQvMJIToHK8N69stHdcomoiJCd5B7B1jEKk6NQjkP3Skcqytr6VNdtaWb2thTca2ni9vo1129voTO+6DWcyZhxd3cHRFU0cGm/i4PB2xrt6qjMNlHfVE26rw9q3wzFLhE8AAA0NSURBVJ5hARCOQeUESB4EFeOhvGZXYJSPgYqx3s9EtT+/GiLxQfwtiAwf6hHIgCuLhZk9eRSzJ4/abX4u59jc1MHr9W28Xt/K+h3tvLm9nQd3tLNpYwcd6exu7RPREBOScWqTOaZXpJgeb2VKpJEJtpPRue1UZbeT6GwgtHMdbH4OOnZCpqP3wqLlXigkqr0eRfloLzjKqr15iVG7h0iswlsmkoBomXogEkgKAhlQoZAxpaacKTXlnHT47neTc86xsz3Npp0dbGrsYLP/qGvuZFtzF3+vC1PXbKQyFRTe1TRkMLYyzsRRCSaMTzClEqbGO5gca2N8uI3qUBtVtFGZayGaaoKORi8wOnbAtlXQvgM6G3vudexWfGRXWMQrIVrhnR0VT0K8ChJVfsCM8QImMQpiST9MEt7yoajXK4lXQajUNwAU6R8FgQwaM2N0RYzRFTHmTBnVYxvnHI3tabY0dbK1uZO65k62NHVS19RBXXMXbzS08eTaTpo783/UE/5jDADJRITxyTjjknGqy2JUT4wyqixKVSLCmHiGceFOxoRaqKGZUa6ZynCKSLYL0u3Q2ewFRkcjpFoh1Q7t22Hneuhsgq5myHT2c2dDXhiUVe8KkngSYpVeyMQqvR5IJOH1SGIV/vykNz9a7oVLJLGrt5Jvr16LDDAFgQwpZkZNRYyaihgzJ1X12q4znaW+pYv61i52tKbY3tZFQ2uK+pYutrV0Ut/SxesNrTS2p2nsSJPK5PZYgwFeGI2uiDE+GaeqLEoyHqEyEaG6MkpNRYwxFTGqyqLeIxGlOppmFK0ks83Es21+YLRCutPrceQykO7YFSidTdDV4oVI8ybo8tt3tfY9xNXrLyjkD2XFvVAIxwoCZY+fkbjXSwlHvXb5R37ZaAIiZd50tAzCcQj7vZr8MpH47suGo7uWD4X3vX4ZkhQEMiwlomGmji5n6uj+fbGtM52lqSPNzvYUO9vSNLan2N6WoqG1i20tXdS3dNHckaauuZOWbRka21MFvY6exSMhkokoVWVjqEp4PY9RZVGSiQiV8QgViQgVoyJUxsNUxCNUxCMk4xGSiXybMJXhLKFMh9cj6WqFVJv3PNPp/Ux3eoGR7oR0m9dLyb+eSUG2ywueTKf3s2MntNR5y2RSkEtDNv/w2w+U/FBYOOYFSDjmT0e8UInE/J/xXcGU/9kdSHE/gGIFIRTbtWw46oWfhfztRXpulw+8wp+Fj/w89aZ6pCCQQEhEwySiYQ6q6v+X3dLZHDvbUzR3ZGjuTNPUkaalM0NTR5rmjjTNnenu15o7vHBZv72N5s4MrV2ZHnohb2UGlTEvJCr9AEkmYlTGy6mMj6cy4YVHRTxCeTxCeXmYsliYsmiYeDREIuo9L4/tmp+IhomEDOvpj55zXiBkOiFTECL56Wy6IDxS/rxUQZD48zJd3jK5NGQz3vzC59muXUGV6YL2Bi/Mdpvv1zGQ4bQ3vYVXKOwHRg8hlH/NwgXtoruWywdVYViFQrtvJ9/Lygdlvp3ll7eCdRVsJxQuWE/UO+W6auLe93MfKQhEehENhxifTDA+uX/Lp7M52rq8UGhPZWnxA6Kl0wuU1k7veXNnhrauDG2pTHebuqZOWvz5rakM+3qWd8igPBahPOb1RuKRELFIiEjIiEVClMci3aERj4ZIRKIkonFikRDxSJh4JOSHZ8gLnbg3PxYJEQuHiIa99ZXFwpRHvRCKR0I9h8/eOOcNqRWGUKbLC4hsBlwOXHbX0FsuWxBKfqhk0978XHpXu2y+vR9Q+XXvFlgpf7lML9v2X+/efragVn/9zhXUmH1rHQNp0VXwz9cO7DpREIgUTTQcoro8RnV57IDWk8s52tNZ2lMZOlJZ2lNZOtNZOtM5OjNZOv157amMNy+dpTOTpSOVoz2VoS2VpSOVJZPLkck6ujLe8ZWOtDe/K5PtXi6T2//vFZnRHSD54ImFQ929sTI/WOIRL3zygROLhIiGjVg47AdRyO/dxIlHyoiGQ0TCRiwcIhL22kajIWJluwIp6r/uPQ/13iMabM7t0ctKe4GRDxKX84Mk6z3vDh1/Ot8u3yurqS1KmQoCkSEuFDIq496wUbFlc45UJtcdDh1pL3S8ed78VCZHOutN54Mp3y4fUN1tsjm60rvWtbM91d2mK5MjlcmSynrtDyCD3sLMC+J4OETUD6R8YETDXthEC4LDe24Fz71lIiEjmm8b3vW6t04jEvJCKh8+kbARDvnLFQRYOGREQmEi4eiu12L59VnJw0tBICLdwiHzPo3HBv+MoHwI7erRZOnKeL2YdC5HOpMjk3PdwZHOeo9UJkcq60hncqSyXrt8CKUyux57Lpuf35bKdi+byeZIZ523XX+bKX/eYAiHzA8N6w4ML3i85xfMP5iPn3TIgG9XQSAiQ0IpQ2hvnHNkcq47QNJZ1x1E6azrHnbL5rx2meyu4Elncrvm5/z22V3P09ldIZfNeaGXze7aXsZvk8rmGJcsziVUFAQiInthZt1DOAd4yGdI0nfgRUQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMANu5vXm1k9sH4/Fx8LNAxgOcNFEPc7iPsMwdzvIO4z7Pt+T3POjevphWEXBAfCzJY55+aVuo7BFsT9DuI+QzD3O4j7DAO73xoaEhEJOAWBiEjABS0Ibip1ASUSxP0O4j5DMPc7iPsMA7jfgTpGICIibxW0HoGIiOxBQSAiEnCBCQIzO83MXjWzNWZ2TanrKQYzm2pmD5vZy2b2kpld6c8fbWZ/NbPV/s+aUtdaDGYWNrPnzOyP/vR0M3vaf8/vMLMRdUsRM6s2s7vM7BUzW2VmxwfhvTaz/+v/+15pZreZWWIkvtdmdrOZbTOzlQXzenx/zbPE3/8XzOzYfdlWIILAzMLADcBiYCZwgZnNLG1VRZEBPuOcmwksBC739/Ma4O/OuRnA3/3pkehKYFXB9HXA95xzhwE7gX8rSVXF89/An51zbwOOxtv3Ef1em9lk4ApgnnNuNhAGzmdkvte/BE7bY15v7+9iYIb/uBT48b5sKBBBACwA1jjnXnfOpYDbgfeVuKYB55zb4pxb7j9vwfvDMBlvX2/xm90CnFWaCovHzKYAZwA/86cNeBdwl99kRO23mY0CTgJ+DuCcSznnGgnAe413i90yM4sA5cAWRuB77ZxbCuzYY3Zv7+/7gFud5ymg2swm9ndbQQmCycCGgumN/rwRy8xqgWOAp4GDnHNb/JfqgINKVFYxfR/4HJDzp8cAjc65jD890t7z6UA98At/OOxnZlbBCH+vnXObgOuBN/ECoAl4lpH9Xhfq7f09oL9xQQmCQDGzSuBu4CrnXHPha847X3hEnTNsZv8CbHPOPVvqWgZRBDgW+LFz7higjT2GgUboe12D9+l3OjAJqOCtwyeBMJDvb1CCYBMwtWB6ij9vxDGzKF4I/MY5d48/e2u+m+j/3Faq+opkEXCmma3DG/Z7F974ebU/fAAj7z3fCGx0zj3tT9+FFwwj/b3+J+AN51y9cy4N3IP3/o/k97pQb+/vAf2NC0oQPAPM8M8siOEdXLqvxDUNOH9c/OfAKufcdwteug/4iP/8I8DvB7u2YnLO/YdzbopzrhbvvX3IOXch8DDwfr/ZiNpv51wdsMHMjvBnvRt4mRH+XuMNCS00s3L/33t+v0fse72H3t7f+4CL/LOHFgJNBUNIe+ecC8QDOB14DVgLfKHU9RRpH9+B11V8AVjhP07HGy//O7Aa+BswutS1FvF3cArwR//5IcA/gDXA/wDxUtc3wPs6F1jmv9/3AjVBeK+Ba4FXgJXAr4D4SHyvgdvwjoOk8XqA/9bb+wsY3pmRa4EX8c6q6ve2dIkJEZGAC8rQkIiI9EJBICIScAoCEZGAUxCIiAScgkBEJOAUBCJ7MLOsma0oeAzYhdvMrLbwapIiQ0Fk701EAqfDOTe31EWIDBb1CET6yczWmdm3zOxFM/uHmR3mz681s4f868D/3cwO9ucfZGa/M7Pn/ccJ/qrCZvZT/5r6fzGzspLtlAgKApGelO0xNHRewWtNzrk5wA/xrngK8APgFufcUcBvgCX+/CXAo865o/GuA/SSP38GcINzbhbQCJxT5P0R6ZO+WSyyBzNrdc5V9jB/HfAu59zr/sX96pxzY8ysAZjonEv787c458aaWT0wxTnXVbCOWuCvzruxCGb2eSDqnPtq8fdMpGfqEYjsG9fL833RVfA8i47VSYkpCET2zXkFP5/0nz+Bd9VTgAuBx/znfwc+Ad33Ux41WEWK7At9EhF5qzIzW1Ew/WfnXP4U0hozewHvU/0F/rxP4d0p7Gq8u4Zd4s+/ErjJzP4N75P/J/CuJikypOgYgUg/+ccI5jnnGkpdi8hA0tCQiEjAqUcgIhJw6hGIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjA/X9qPhbUhgv5SQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La6qMTszveun",
        "outputId": "78ef544f-6aaf-4bc7-8db2-d676109b8f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "# 全てのデータで学習\n",
        "\n",
        "# ハイパーパラメータの設定 w(F,C,Hf,Wf) b(F)\n",
        "W1 = np.array((5,1,5,5)); B1 = 5\n",
        "W2 = np.array((320,10)); B2 = 10\n",
        "\n",
        "# 4層のConvネットワーク\n",
        "layer_1 = Layer(Conv2d(), ReLu(), HeInitializer(), AdaGrad(), 784, W1, B1)  # 1,28,28 to 5,24,24\n",
        "layer_2 = Layer(None, Pool2d((3,3))) # 5,24,24 to 5,8,8\n",
        "layer_3 = Layer(None, Flatten())  # 5,8,8 to 320\n",
        "output = Layer(Affine(), Softmax(), XavierInitializer(), AdaGrad(), 320, W2, B2)  # 320 to 10\n",
        "\n",
        "params = {'epoch': 50, \n",
        "          'lr': 0.01,\n",
        "          'batch_size': 200,\n",
        "          }\n",
        "\n",
        "cnn = ScratchConvNeuralNetworkClassifier(layers=[layer_1, layer_2, layer_3, output], verbose=True, **params)\n",
        "\n",
        "cnn.fit(X_train, y_train, X_val, y_val)\n",
        "\n",
        "pred = cnn.predict(X_test)\n",
        "\n",
        "print(\"\\n Accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "plot_loss(cnn)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10; Loss 0.2535   --Avg Epoch Time 105.1018sec\n",
            "Epoch 20; Loss 0.2144   --Avg Epoch Time 106.2292sec\n",
            "Epoch 30; Loss 0.1980   --Avg Epoch Time 106.1294sec\n",
            "Epoch 40; Loss 0.1880   --Avg Epoch Time 106.6545sec\n",
            "Epoch 50; Loss 0.1811   --Avg Epoch Time 105.5445sec\n",
            "\n",
            " Accuracy: 0.9496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}