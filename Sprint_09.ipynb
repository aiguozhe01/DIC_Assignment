{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sprint_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiguozhe01/DIC_Assignment/blob/master/Sprint_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K6hgSnqGHtP"
      },
      "source": [
        "# Sprint 深層学習スクラッチ ニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkQo57cIGHtQ",
        "outputId": "adb93d6d-95c4-4baf-ae2c-893552b183fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "from fractions import Fraction\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXTWJorJGHtS"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktcEyNOJGHtU",
        "outputId": "74d1c193-592f-49af-a033-f0b3b0cba31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "# X_train[index]: (784,)\n",
        "# image: (28, 28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcEJqYmcGHtW",
        "outputId": "f1f94326-acd9-44f4-9b8a-e609f4575adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "\n",
        "image = image.astype(np.float) # float型に変換\n",
        "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
        "\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()\n",
        "print(image) # 値を確認"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
            "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
            "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
            "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
            "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
            "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
            "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
            "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
            "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
            "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
            "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
            "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
            "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
            "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
            "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
            "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
            "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
            "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
            "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfQOcve5GHtY",
        "outputId": "5b16d942-dd9f-414b-bbf7-d479e7b61424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_nqBUNhGHta",
        "outputId": "1ddf829c-140f-4361-c5b0-cf5821c05a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGtKXdKzGHtc",
        "outputId": "d51a40bd-a957-401b-9cc2-74906ccc700a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3d4twp7GHte"
      },
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "class Linear:\n",
        "    \"\"\"\n",
        "    線形結合\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dZ_ : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "      逆伝播入力に対するdZ勾配\n",
        "    dw_ : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "      逆伝播入力に対するdw勾配\n",
        "    db_ : 次の形のndarray, shape (n_nodes_self, )\n",
        "      逆伝播入力に対するdb勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        b : 次の形のndarray, shape (n_nodes_self, )\n",
        "          ある層のバイアス\n",
        "        \"\"\"\n",
        "        self.A_ = Z @ w + b\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたAに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dZ_ = dA @ w.T\n",
        "        self.dw_ = Z.T @ dA\n",
        "        self.db_ = np.sum(dA, axis=0)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "\n",
        "        \n",
        "class Sigmoid:\n",
        "    \"\"\"\n",
        "    シグモイド関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = 1 / (1+np.exp(-A))\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * ((1 - self.Z_) * self.Z_)\n",
        "    \n",
        "        return self.dA_\n",
        "        \n",
        "        \n",
        "class Tanh:\n",
        "    \"\"\"\n",
        "    ハイパーボリックタンジェント関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = np.tanh(A)\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * (1 - self.Z_**2)\n",
        "        \n",
        "        return self.dA_\n",
        "\n",
        "    \n",
        "class Softmax:\n",
        "    \"\"\"\n",
        "    SoftMax関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        # オーバーフロー対策として定数を引き算する\n",
        "        C = np.max(A)\n",
        "        self.Z_ = np.exp(A - C) / np.sum(np.exp(A - C), axis=1)[:, None]\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, y):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          正解ラベルデータ\n",
        "        \"\"\"\n",
        "        self.dA_ = self.Z_ - y\n",
        "        \n",
        "        return self.dA_\n",
        "                         \n",
        "        \n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "    \n",
        "        \n",
        "class ScratchSimpleNeuralNetworkClassifier():\n",
        "    \"\"\"\n",
        "    シンプルな三層ニューラルネットワーク分類器\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    epoch : int\n",
        "      エポック数\n",
        "    lr : float\n",
        "      学習率\n",
        "    sigma : float\n",
        "      初期パラメータ用\n",
        "    n_nodes1 : int\n",
        "      1層目のノード数\n",
        "    n_nodes2 : int\n",
        "      2層目のノード数\n",
        "    n_output : int\n",
        "      出力層のノード数\n",
        "    batch_size : int\n",
        "      ミニバッチのサンプル数\n",
        "      \n",
        "    Attributes\n",
        "    ----------\n",
        "    w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "      重みパラメータ\n",
        "    b : 次の形のndarray, shape (n_nodes_self, )\n",
        "      バイアスパラメータ\n",
        "    loss_train : list\n",
        "      訓練データに対するLoss\n",
        "    loss_val : list\n",
        "      検証データに対するLoss\n",
        "    verbose : bool\n",
        "      学習経過の出力\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, epoch=10, sigma=0.1, lr=0.1, n_nodes1=400, n_nodes2=200, n_output=10, batch_size=20, verbose=False, **kwargs):\n",
        "        self.epoch = epoch\n",
        "        self.lr = lr\n",
        "        self.sigma = sigma\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.n_output = n_output\n",
        "        self.batch_size = batch_size\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        self.verbose = verbose\n",
        "\n",
        "\n",
        "    def _params_init(self, n_features, n_output):\n",
        "        \"\"\"\n",
        "        3層ニューラルネット用のパラメータ初期化関数\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        w_params : list\n",
        "          各層の重みを格納したリスト\n",
        "        b_params : list\n",
        "          各層のバイアスを格納したリスト\n",
        "        \"\"\"\n",
        "        W1 = self.sigma * np.random.randn(n_features, self.n_nodes1)\n",
        "        W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
        "        W3 = self.sigma * np.random.randn(self.n_nodes2, n_output)\n",
        "\n",
        "        B1 = np.random.randn(self.n_nodes1)\n",
        "        B2 = np.random.randn(self.n_nodes2)\n",
        "        B3 = np.random.randn(n_output)\n",
        "\n",
        "        w_params = np.array((W1, W2, W3))\n",
        "        b_params = np.array((B1, B2, B3))\n",
        "\n",
        "        return w_params, b_params\n",
        "    \n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, n_classes)\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, n_classes)\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        w, b = self._params_init(len(X[0]), self.n_output)\n",
        "\n",
        "        # レイヤーインスタンスを作成\n",
        "        linear_1 = copy.deepcopy(Linear())\n",
        "        activ_1 = copy.deepcopy(Sigmoid())\n",
        "        linear_2 = copy.deepcopy(Linear())\n",
        "        activ_2 = copy.deepcopy(Sigmoid())\n",
        "        linear_3 = copy.deepcopy(Linear())\n",
        "        softmax = copy.deepcopy(Softmax())\n",
        "\n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            \n",
        "            get_mini_batch_t = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            \n",
        "            times = []\n",
        "            \n",
        "            start = time.time()\n",
        "            \n",
        "            # 各mini batchの損失をリスト化\n",
        "            loss_batch_t = []\n",
        "            \n",
        "            for X_mini, y_mini in get_mini_batch_t:\n",
        "                \n",
        "                # 順伝播\n",
        "                A1 = linear_1.forward(X_mini, w[0], b[0])\n",
        "                Z1 = activ_1.forward(A1)\n",
        "\n",
        "                A2 = linear_2.forward(Z1, w[1], b[1])\n",
        "                Z2 = activ_2.forward(A2)\n",
        "\n",
        "                A3 = linear_3.forward(Z2, w[2], b[2])\n",
        "                Z3 = softmax.forward(A3)\n",
        "\n",
        "                # 逆伝播\n",
        "                dA3 = softmax.backward(y_mini)\n",
        "                dZ2, dw3, db3 = linear_3.backward(Z2, w[2], dA3)\n",
        "\n",
        "                dA2 = activ_2.backward(dZ2)\n",
        "                dZ1, dw2, db2 = linear_2.backward(Z1, w[1], dA2)\n",
        "\n",
        "                dA1 = activ_1.backward(dZ1)\n",
        "                _, dw1, db1 = linear_1.backward(X_mini, w[0], dA1)\n",
        "\n",
        "                # 確率的勾配降下法\n",
        "                w -= self.lr * np.array((dw1, dw2, dw3)) \n",
        "                b -= self.lr * np.array((db1, db2, db3)) \n",
        "                \n",
        "                # 損失関数\n",
        "                loss_batch_t.append(self.cross_entropy(Z3, y_mini, len(X_mini)))\n",
        "            \n",
        "            # 各epochの平均損失をselfに格納\n",
        "            loss_train = np.mean(loss_batch_t)\n",
        "            self.loss_train.append(loss_train)\n",
        "            \n",
        "            \n",
        "            # 検証データの推定\n",
        "            if hasattr(X_val, '__array__') and hasattr(y_val, '__array__'):\n",
        "                \n",
        "                batch_size_v = int(self.batch_size * len(X_val)/len(X))\n",
        "                get_mini_batch_v = GetMiniBatch(X_val, y_val, batch_size=batch_size_v)\n",
        "                loss_batch_v = []\n",
        "\n",
        "                for X_mini, y_mini in get_mini_batch_v:\n",
        "                    A1 = linear_1.forward(X_mini, w[0], b[0])\n",
        "                    Z1 = activ_1.forward(A1)\n",
        "\n",
        "                    A2 = linear_2.forward(Z1, w[1], b[1])\n",
        "                    Z2 = activ_2.forward(A2)\n",
        "\n",
        "                    A3 = linear_3.forward(Z2, w[2], b[2])\n",
        "                    Z3 = softmax.forward(A3)\n",
        "                \n",
        "                    loss_batch_v.append(self.cross_entropy(Z3, y_mini, len(X_mini)))\n",
        "            \n",
        "                # 各epochの平均損失をselfに格納\n",
        "                loss_val = np.mean(loss_batch_v)\n",
        "                self.loss_val.append(loss_val)\n",
        "            \n",
        "            end = time.time()\n",
        "            \n",
        "            times.append(end-start)\n",
        "\n",
        "\n",
        "            if self.verbose and (i+1) % 10 == 0:\n",
        "                print(\"Epoch {}; Loss {:.4f}\".format(i+1, loss_train),\n",
        "                      \"  --Avg Epoch Time {:.4f}sec\".format(np.mean(times)))\n",
        "                \n",
        "        # 全epoch終了後のパラメータを保存    \n",
        "        self.w = w\n",
        "        self.b = b\n",
        "\n",
        "            \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を使い推定する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, )\n",
        "            推定結果\n",
        "        \"\"\"\n",
        "        A1 = Linear().forward(X, self.w[0], self.b[0])\n",
        "        Z1 = Sigmoid().forward(A1)\n",
        "\n",
        "        A2 = Linear().forward(Z1, self.w[1], self.b[1])\n",
        "        Z2 = Sigmoid().forward(A2)\n",
        "\n",
        "        A3 = Linear().forward(Z2, self.w[2], self.b[2])\n",
        "        Z3 = Softmax().forward(A3)\n",
        "        \n",
        "        return np.argmax(Z3, axis=1)\n",
        "        \n",
        "    \n",
        "    def cross_entropy(self, X, y, batch_size):\n",
        "        \"\"\"\n",
        "        クロスエントロピー誤差を計算\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_features)\n",
        "          入力データ\n",
        "        y : 次の形のndarray, shape (batch_size, n_classes)\n",
        "          入力データの正解ラベル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "          float\n",
        "          クロスエントロピー誤差\n",
        "        \"\"\"\n",
        "        return (-1/batch_size) * np.sum((y*np.log(X)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFKa7d0-GHtj"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT34WBA8GHtl",
        "outputId": "92d35d6e-ee0f-47fb-bc78-4b752dc90b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
        "print(len(get_mini_batch)) # 2400\n",
        "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
        "for mini_X_train, mini_y_train in get_mini_batch:\n",
        "    # このfor文内でミニバッチが使える\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n",
            "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]]), array([9, 0, 4, 3, 8, 0, 7, 6, 3, 2, 6, 7, 3, 8, 1, 4, 7, 0, 6, 0],\n",
            "      dtype=uint8))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mxjwiFUGHtn"
      },
      "source": [
        "## 【問題1】重みの初期値を決めるコードの作成\n",
        "\n",
        "1. ニューラルネットワークの各層の重みの初期値を決めるコードを作成する。\n",
        "    * 重みの初期値はガウス（正規）分布による単純な初期化を行う。\n",
        "    * バイアスに関しても同様\n",
        "    * サンプルコードの標準偏差の値sigmaはハイパーパラメータ。\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5HAABbgGHtn"
      },
      "source": [
        "n_features = 784\n",
        "n_nodes1 = 400\n",
        "n_nodes2 = 200\n",
        "n_output = 10\n",
        "sigma = 0.01 # ガウス分布の標準偏差\n",
        "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
        "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
        "# W1: (784, 400)\n",
        "\n",
        "#################\n",
        "# he_initialization = np.random.randn(size_l, size_l_1) * np.sqrt(2/size_l_1)\n",
        "# xavier_initialization = np.random.randn(size_l, size_l_1) * np.sqrt(1/size_l_1)\n",
        "# Xavier initialization which considers the size of the network(number of input and output units) while initializing weights.\n",
        "#################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDR2CILrG9N3"
      },
      "source": [
        "def params_init_():\n",
        "    \"\"\"\n",
        "    3層ニューラルネット用のパラメータ初期化関数\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    w_params : list\n",
        "      各層の重みを格納したリスト\n",
        "    b_params : list\n",
        "      各層のバイアスを格納したリスト\n",
        "    \"\"\"\n",
        "    n_features = 784\n",
        "    n_nodes1 = 400\n",
        "    n_nodes2 = 200\n",
        "    n_output = 10\n",
        "    sigma = 0.01 # ガウス分布の標準偏差\n",
        "\n",
        "    W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
        "    W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "    W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
        "\n",
        "    B1 = sigma * np.random.randn(n_nodes1)\n",
        "    B2 = sigma * np.random.randn(n_nodes2)\n",
        "    B3 = sigma * np.random.randn(n_output)\n",
        "    \n",
        "    w_params = np.array((W1, W2, W3))\n",
        "    b_params = np.array((B1, B2, B3))\n",
        "    \n",
        "    return w_params, b_params"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjubKl77G_3w",
        "outputId": "eddfcb2b-6d99-4578-e8bd-d009bb2f9991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "w, b = params_init_()\n",
        "print(w[0].shape)\n",
        "print(b[0].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 400)\n",
            "(400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z3lEoDuGHtp"
      },
      "source": [
        "## 【問題2】フォワードプロパゲーションの実装\n",
        "\n",
        "1. 三層のニューラルネットワークの**フォワードプロパゲーション**を作成する。\n",
        "    * batch_size = 20 # バッチサイズ\n",
        "    * n_features = 784 # 特徴量の数\n",
        "    * n_nodes1 = 400 # 1層目のノード数\n",
        "    * n_nodes2 = 200 # 2層目のノード数\n",
        "    * n_output = 10 # 出力のクラス数（3層目のノード数）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "ks00vQqlGHtp"
      },
      "source": [
        "class Linear:\n",
        "    \"\"\"\n",
        "    線形結合\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        b : 次の形のndarray, shape (n_nodes_self, )\n",
        "          ある層のバイアス\n",
        "        \"\"\"\n",
        "        self.A_ = Z @ w + b\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "        \n",
        "class Sigmoid:\n",
        "    \"\"\"\n",
        "    シグモイド関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = 1 / (1+np.exp(-A))\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "        \n",
        "class Tanh:\n",
        "    \"\"\"\n",
        "    ハイパーボリックタンジェント関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = np.tanh(A)\n",
        "        \n",
        "        return self.Z_\n",
        "\n",
        "    \n",
        "class Softmax:\n",
        "    \"\"\"\n",
        "    SoftMax関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        # オーバーフロー対策として定数を引き算する\n",
        "        C = np.max(A)\n",
        "        self.Z_ = np.exp(A - C) / np.sum(np.exp(A - C), axis=1)[:, None]\n",
        "        \n",
        "        return self.Z_\n",
        "                         \n",
        "\n",
        "def fit(X):\n",
        "    \"\"\"\n",
        "    ニューラルネットワーク分類器を学習する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "        訓練データの特徴量\n",
        "    \"\"\"\n",
        "    w, b = params_init_()\n",
        "    \n",
        "    # レイヤーインスタンスを作成\n",
        "    linear_1 = Linear()\n",
        "    sigmoid_1 = Sigmoid()\n",
        "    linear_2 = Linear()\n",
        "    sigmoid_2 = Sigmoid()\n",
        "    linear_3 = Linear()\n",
        "    softmax = Softmax()\n",
        "    \n",
        "    A1 = linear_1.forward(X, w[0], b[0])\n",
        "    print(A1.shape)\n",
        "    Z1 = sigmoid_1.forward(A1)\n",
        "    print(Z1.shape)\n",
        "    A2 = linear_2.forward(Z1, w[1], b[1])\n",
        "    print(A2.shape)\n",
        "    Z2 = sigmoid_2.forward(A2)\n",
        "    print(Z2.shape)\n",
        "    A3 = linear_3.forward(Z2, w[2], b[2])\n",
        "    print(A3.shape)\n",
        "    Z3 = softmax.forward(A3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzyNNGLYGHtr",
        "outputId": "6131cc02-21e8-491a-e194-ccdcfc019dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "fit(X_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 400)\n",
            "(48000, 400)\n",
            "(48000, 200)\n",
            "(48000, 200)\n",
            "(48000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4bRpd3SGHtv"
      },
      "source": [
        "## 【問題3】交差エントロピー誤差の実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9HOUnDxGHtv"
      },
      "source": [
        "def cross_entropy(X, y, batch_size):\n",
        "    \"\"\"\n",
        "    クロスエントロピー誤差を計算\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (batch_size, n_features)\n",
        "      入力データ\n",
        "    y : 次の形のndarray, shape (batch_size, n_classes)\n",
        "      入力データの正解ラベル\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "      float\n",
        "      クロスエントロピー誤差\n",
        "    \"\"\"\n",
        "    return (-1/batch_size) * np.sum((y*np.log(X)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9l5FkwIGHtz"
      },
      "source": [
        "## 【問題4】バックプロパゲーションの実装\n",
        "勾配 \n",
        "$∂L∂Wi$ や $∂L∂Bi$ を求めるために、バックプロパゲーションを行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eZusJIAGHtz"
      },
      "source": [
        "class Linear:\n",
        "    \"\"\"\n",
        "    線形結合\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dZ_ : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "      逆伝播入力に対するdZ勾配\n",
        "    dw_ : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "      逆伝播入力に対するdw勾配\n",
        "    db_ : 次の形のndarray, shape (n_nodes_self, )\n",
        "      逆伝播入力に対するdb勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        b : 次の形のndarray, shape (n_nodes_self, )\n",
        "          ある層のバイアス\n",
        "        \"\"\"\n",
        "        self.A_ = Z @ w + b\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
        "          ある層の重み\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたAに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dZ_ = dA @ w.T\n",
        "        self.dw_ = Z.T @ dA\n",
        "        self.db_ = np.sum(dA, axis=0)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "\n",
        "        \n",
        "class Sigmoid:\n",
        "    \"\"\"\n",
        "    シグモイド関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = 1 / (1+np.exp(-A))\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * ((1 - self.Z_) * self.Z_)\n",
        "    \n",
        "        return self.dA_\n",
        "        \n",
        "        \n",
        "class Tanh:\n",
        "    \"\"\"\n",
        "    ハイパーボリックタンジェント関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        self.Z_ = np.tanh(A)\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に逆伝播されたZに関するLoss勾配\n",
        "        \"\"\"\n",
        "        self.dA_ = dZ * (1 - self.Z_**2)\n",
        "        \n",
        "        return self.dA_\n",
        "\n",
        "    \n",
        "class Softmax:\n",
        "    \"\"\"\n",
        "    SoftMax関数\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      順伝播の出力\n",
        "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "      逆伝播入力に対するdA勾配\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          ある層に順伝播された特徴量データ\n",
        "        \"\"\"\n",
        "        # オーバーフロー対策として定数を引き算する\n",
        "        C = np.max(A)\n",
        "        self.Z_ = np.exp(A - C) / np.sum(np.exp(A - C), axis=1)[:, None]\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, y):\n",
        "        \"\"\"\n",
        "        逆伝播\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
        "          正解ラベルデータ\n",
        "        \"\"\"\n",
        "        self.dA_ = self.Z_ - y\n",
        "        \n",
        "        return self.dA_\n",
        "                         \n",
        "\n",
        "def fit(X, y, num_iter, lr=0.1, verbose=False):\n",
        "    \"\"\"\n",
        "    ニューラルネットワーク分類器を学習する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データの特徴量\n",
        "    y : 次の形のndarray, shape (n_samples, n_classes)\n",
        "      訓練データの正解値\n",
        "    num_iter : int\n",
        "      イテレーション数\n",
        "    lr : float\n",
        "      学習率\n",
        "    verbose : bool\n",
        "      学習経過の出力\n",
        "    \"\"\"\n",
        "    w, b = params_init_()\n",
        "    y = y.reshape(-1, 1)\n",
        "    \n",
        "    # レイヤーインスタンスを作成\n",
        "    linear_1 = Linear()\n",
        "    sigmoid_1 = Sigmoid()\n",
        "    linear_2 = Linear()\n",
        "    sigmoid_2 = Sigmoid()\n",
        "    linear_3 = Linear()\n",
        "    softmax = Softmax()\n",
        "    \n",
        "    progress = []\n",
        "    \n",
        "    for i in range(num_iter):\n",
        "    \n",
        "        # 順伝播\n",
        "        A1 = linear_1.forward(X, w[0], b[0])\n",
        "        Z1 = sigmoid_1.forward(A1)\n",
        "        \n",
        "        A2 = linear_2.forward(Z1, w[1], b[1])\n",
        "        Z2 = sigmoid_2.forward(A2)\n",
        "        \n",
        "        A3 = linear_3.forward(Z2, w[2], b[2])\n",
        "        Z3 = softmax.forward(A3)\n",
        "        \n",
        "        # 逆伝播\n",
        "        dA3 = softmax.backward(y)\n",
        "        dZ2, dw3, db3 = linear_3.backward(Z2, w[2], dA3)\n",
        "        \n",
        "        dA2 = sigmoid_2.backward(dZ2)\n",
        "        dZ1, dw2, db2 = linear_2.backward(Z1, w[1], dA2)\n",
        "\n",
        "        dA1 = sigmoid_1.backward(dZ1)\n",
        "        _, dw1, db1 = linear_1.backward(X, w[0], dA1)\n",
        "        \n",
        "        # 確率的勾配降下法\n",
        "        w -= lr * np.array((dw1, dw2, dw3)) \n",
        "        b -= lr * np.array((db1, db2, db3)) \n",
        "        print(w)\n",
        "        \n",
        "        #損失関数\n",
        "        loss = calc_loss(Z3, y, len(X))\n",
        "        progress.append(loss)\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"Iteration {}; Loss {:.4f}\".format(i+1, loss))\n",
        "        \n",
        "    return Z3"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M0iYFgzHfj4"
      },
      "source": [
        "## 【問題５】推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv_Eq-AwGHt1"
      },
      "source": [
        "def predict(self, X):\n",
        "    \"\"\"\n",
        "    ニューラルネットワーク分類器を使い推定する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "        サンプル\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        次の形のndarray, shape (n_samples, )\n",
        "        推定結果\n",
        "    \"\"\"\n",
        "\n",
        "    A1 = Linear().forward(X, self.w[0], self.b[0])\n",
        "    Z1 = Sigmoid().forward(A1)\n",
        "\n",
        "    A2 = Linear().forward(Z1, self.w[1], self.b[1])\n",
        "    Z2 = Sigmoid().forward(A2)\n",
        "\n",
        "    A3 = Linear().forward(Z2, self.w[2], self.b[2])\n",
        "    Z3 = Softmax().forward(A3)\n",
        "\n",
        "    return np.argmax(Z3, axis=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMBLGwjvHk_4"
      },
      "source": [
        "## 【問題6】学習と推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYh0HLzNIOki"
      },
      "source": [
        "#《データセットをダウンロードするコード》\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw_EmK3IIMVn"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iCfOjuLH7Wk",
        "outputId": "f103c644-9b4e-4cb4-b292-f17a39c35953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb23LwziIHtt",
        "outputId": "b93d615e-af14-45fd-ff70-fc2ad33cf72a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0MFI8stIVBh",
        "outputId": "02e419ac-e487-45d0-b652-80a864a6e90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWu6DhiRHkzD",
        "outputId": "5bada5b3-3d13-4ba6-b096-068022d49827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "params = {'epoch': 100, \n",
        "          'lr': 0.01,\n",
        "          'sigma':  0.1,\n",
        "          'batch_size': 200}\n",
        "print(params)\n",
        "\n",
        "scratch_nn = ScratchSimpleNeuralNetworkClassifier(verbose=True, **params)\n",
        "scratch_nn.fit(X_train, y_train, X_val, y_val)\n",
        "\n",
        "pred = scratch_nn.predict(X_test)\n",
        "\n",
        "print(\"\\n Accuracy: {}\".format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'epoch': 100, 'lr': 0.01, 'sigma': 0.1, 'batch_size': 200}\n",
            "Epoch 10; Loss 0.0598   --Avg Epoch Time 10.1362sec\n",
            "Epoch 20; Loss 0.0148   --Avg Epoch Time 7.0748sec\n",
            "Epoch 30; Loss 0.0043   --Avg Epoch Time 7.1089sec\n",
            "Epoch 40; Loss 0.0019   --Avg Epoch Time 7.3959sec\n",
            "Epoch 50; Loss 0.0012   --Avg Epoch Time 7.0971sec\n",
            "Epoch 60; Loss 0.0009   --Avg Epoch Time 7.2085sec\n",
            "Epoch 70; Loss 0.0007   --Avg Epoch Time 7.1578sec\n",
            "Epoch 80; Loss 0.0005   --Avg Epoch Time 7.5461sec\n",
            "Epoch 90; Loss 0.0005   --Avg Epoch Time 7.0882sec\n",
            "Epoch 100; Loss 0.0004   --Avg Epoch Time 7.6087sec\n",
            "\n",
            " Accuracy: 0.9799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02OxMM3ZIcjt"
      },
      "source": [
        "## 【問題７】学習曲線のプロット"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTrNIvnZIeq7",
        "outputId": "36eccb5e-1d8d-4f73-d30a-a04f8c7927f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(model, title='Scratch NN Loss'):\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(np.arange(len(model.loss_train)), model.loss_train, label='train loss')\n",
        "    plt.plot(np.arange(len(model.loss_val)), model.loss_val, label='val loss')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "plot_loss(scratch_nn)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO_3tagSGHt3"
      },
      "source": [
        "# 【訂正事項】\n",
        "\n",
        "【問題4】の「3層目」の数式の説明欄\n",
        "* 誤）$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_nodes2)\n",
        "* 正）$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CkPoYzjGHt3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}