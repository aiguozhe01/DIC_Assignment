{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint_20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1u5lT7dw2ZekykaTS2XnbnUUCmTYmfeYY",
      "authorship_tag": "ABX9TyNQNyl0Qvm75WnqSD9w7USX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiguozhe01/DIC_Assignment/blob/master/Sprint_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlgrjtXtUUyL"
      },
      "source": [
        "# Sprint_20 セグメンテーション2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CzFbr4jKmQ6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQQv9ArLUcwJ"
      },
      "source": [
        "## 【問題1】コードレビュー\n",
        "* 共有されたコードのレビューを行え。\n",
        "  * 転移学習を使用したセグメンテーションの精度を改善したコード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV23u0Q7VNgb"
      },
      "source": [
        "### ライブラリーの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqe18zGspbrr",
        "outputId": "c2de4125-8e85-4491-87e7-564d61fb6de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Just change the version.\n",
        "# tf: 1.14.0 \n",
        "# keras: 2.3.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IW66u8S_XXq",
        "outputId": "4eab4902-8244-41e3-d774-08f3be72236b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 97kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.33.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.1)\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw0bo452_daj",
        "outputId": "4e5c2fa0-3ee3-4624-b5af-3448e0a21ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "!pip install keras==2.3.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR3OyCCwVVuF"
      },
      "source": [
        "### pltのサイズ設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVZuJrawVbtN"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4G2SfqeVIZX"
      },
      "source": [
        "### 関数の用意\n",
        "\n",
        "* compute_coverage:\n",
        "  * 塩の含有率を％で算出する。\n",
        "\n",
        "* create_depth_abs_channels:\n",
        "  * 深度用のチャンネルを作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQulngoWVv12"
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abjZO6AIWAkE"
      },
      "source": [
        "### 訓練データと試験データ、「深さ」の読み込み。\n",
        "* 使用データ：[TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxgmAdSpV_aL",
        "outputId": "a8477a63-4073-4d07-89c0-5ae170c63d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/DIC/dataset/TGS_Salt_Identification/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/DIC/dataset/TGS_Salt_Identification/sample_submission.csv')\n",
        "depth = pd.read_csv('/content/drive/My Drive/DIC/dataset/TGS_Salt_Identification/depths.csv')\n",
        "\n",
        "train_src = '/content/drive/My Drive/DIC/dataset/TGS_Salt_Identification/train'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...\n",
            "1  3cb59a4fdc                                             1 5656\n",
            "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...\n",
            "3  c78c89577c                                              101 1\n",
            "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  3e06571ef3      1 1\n",
            "1  a51b08d882      1 1\n",
            "2  c32590b06f      1 1\n",
            "3  15f7a047c7      1 1\n",
            "4  e8827bc832      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...  312\n",
            "1  3cb59a4fdc                                             1 5656  603\n",
            "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...  687\n",
            "3  c78c89577c                                              101 1  236\n",
            "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...  805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlrDjnHclIkU"
      },
      "source": [
        "### 画像データとマスクデータの読み込み、ランダムサンプルの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcoB8hu2le64",
        "outputId": "4a0ad5db-4a48-4b29-b08d-7f9ab0696079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/DIC/dataset/TGS_Salt_Identification/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/DIC/dataset/TGS_Salt_Identification/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmP5panqmBpz",
        "outputId": "e8795366-e100-4a9c-fab5-3b6408e085a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe54374e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5vkyWb3mEMG"
      },
      "source": [
        "### compute_coverage関数を用いて、訓練データとして格納する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44wun77pnODZ"
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZxk0f2For8B"
      },
      "source": [
        "### 学習用のデータの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixgGnRCoq-x",
        "outputId": "af0200c3-692e-40c9-eb42-bc4b03e7a383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
            "(800, 224, 224, 3) (800, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4vMuI6Uo3wF"
      },
      "source": [
        "### ロス関数と測定関数の作成\n",
        "\n",
        "* dice_coef\n",
        "* dice_loss\n",
        "* bce_dice_loss\n",
        "* bce_logdice_loss\n",
        "* lovasz_grad\n",
        "* lovasz_hinge\n",
        "* lovasz_hinge_flat\n",
        "* flatten_binary_scores\n",
        "* lovasz_loss\n",
        "* get_iou_vector\n",
        "* my_iou_metric\n",
        "* my_iou_metric_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP9FJttOo28Z"
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsLFvFL4pnFm"
      },
      "source": [
        "### Encoder features - ResNet50\n",
        "\n",
        "* プール層毎にブロック処理を行う。\n",
        "* プールする前に、中間層から特徴量を抽出できる。\n",
        "* 抽出のための層が加えられる毎に、５層分の特徴量を抽出できる。\n",
        "* defaultの入力サイズ：(224, 224, 3)\n",
        "  * 以降、(None, 112, 112, 64)\n",
        "  * (None, 56, 56, 256)\n",
        "  * (None, 28, 28, 512)\n",
        "  * (None, 14, 14, 1024)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4esNXI5oc_",
        "outputId": "c4de4e87-940b-4d3a-e2d1-754597fd5327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        }
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.33.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=93bc9f1535a9b2add9f5fa52ba3dfc1200add4d9734cad91ef97bf11815f6b76\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlS5xgyS6bsx",
        "outputId": "59533890-72c3-45e2-c44f-167afb2ebcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mb4oZHO6nlW"
      },
      "source": [
        "### Decoder Blocks\n",
        "\n",
        "* デコーダー用のブロックを２つ作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVZtKs8d6it5"
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awZVuH9w94EL"
      },
      "source": [
        "### Model definition:\n",
        "\n",
        "* エンコーダーとデコーダーを結合したモデルの最終型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DlQL2J6-EMG"
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    # encoder1 = base_model.get_layer('conv1_conv').output # activation_1\n",
        "    # encoder2 = base_model.get_layer('conv2_block3_3_conv').output # activation_10\n",
        "    # encoder3 = base_model.get_layer('conv3_block4_2_conv').output # activation_22\n",
        "    # encoder4 = base_model.get_layer('conv4_block6_2_conv').output # activation_40\n",
        "    # encoder5 = base_model.get_layer('conv5_block3_3_conv').output # activation_49\n",
        "\n",
        "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
        "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
        "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
        "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
        "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
        "\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vmK50G4-H3u"
      },
      "source": [
        "### 検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfKhl2ed-Mym",
        "outputId": "1f39bffc-6899-4d01-e907-a08ae01387e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 512)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  589952      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 28, 256)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   147520      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_3[0][0]            \n",
            "                                                                 conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 41,797,953\n",
            "Trainable params: 41,746,817\n",
            "Non-trainable params: 51,136\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22h2lt1M-OX7"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4lR2Goq-eq9",
        "outputId": "e47f27c6-3378-4a71-921f-a646fc30c413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,970,161\n",
            "Trainable params: 48,915,857\n",
            "Non-trainable params: 54,304\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 3200 samples, validate on 800 samples\n",
            "Epoch 1/2\n",
            "3200/3200 [==============================] - 6770s 2s/step - loss: 0.7519 - my_iou_metric: 0.3667 - val_loss: 85.1373 - val_my_iou_metric: 6.2500e-04\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.00062, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3184/3200 [============================>.] - ETA: 31s - loss: 0.5931 - my_iou_metric: 0.4713 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a9fcef2cb510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM-en7P--gh_"
      },
      "source": [
        "### 検証用データの準備\n",
        "* オリジナルサイズに加工"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_SQsqMD-zSF"
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ6UAdSD_Ntm"
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phRmERJvGGGK"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh309mBEGIFY"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpvQBT5BGLI-"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qAwC6rl_F_g"
      },
      "source": [
        "* ResNetを用いることによって、特定の問題解決にセグメンテーション手法が使える。\n",
        "    * モデルによってはエンコーダーとデコーダーの数の調整が必要\n",
        "* 閾値の調整が重要となる。過剰のOptimizationによる閾値の変動が起きないように、訓練データと検証データの近似性は低いことが理想と思われる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kchCXYPmHB8e"
      },
      "source": [
        "## 【問題2】コードの書き換え"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou-YBEzyHBVQ"
      },
      "source": [
        "# VGG16\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v67Yr_OUG_Tw",
        "outputId": "b5d1c75b-b9c7-42c0-a581-f8990ad6eb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_size = (224, 224, 3)\n",
        "\n",
        "vgg_model = VGG16(input_shape=input_size, include_top=False)\n",
        "vgg_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFdX_jlVHNK4"
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_vgg(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    vgg_model = VGG16(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = vgg_model.get_layer('block1_pool').output # (112,112,64)\n",
        "    encoder2 = vgg_model.get_layer('block2_pool').output # (56,56,128)\n",
        "    encoder3 = vgg_model.get_layer('block3_pool').output # (28,28,256)\n",
        "    encoder4 = vgg_model.get_layer('block4_pool').output # (14,14,512)\n",
        "    encoder5 = vgg_model.get_layer('block5_pool').output # (7,7,512)\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(vgg_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxgg2l0-HN15"
      },
      "source": [
        "## 【問題3】学習・推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkrtNA9bHQNx",
        "outputId": "0e61da0d-b95e-4172-f1a2-4459e6351fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_vgg(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 28,677,489\n",
            "Trainable params: 28,672,209\n",
            "Non-trainable params: 5,280\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 3200 samples, validate on 800 samples\n",
            "Epoch 1/2\n",
            "3200/3200 [==============================] - 9573s 3s/step - loss: 0.8159 - my_iou_metric: 0.1937 - val_loss: 0.7185 - val_my_iou_metric: 0.3821\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.38213, saving model to unet_vgg.h5\n",
            "Epoch 2/2\n",
            "3200/3200 [==============================] - 9556s 3s/step - loss: 0.6914 - my_iou_metric: 0.3423 - val_loss: 0.7197 - val_my_iou_metric: 0.3702\n",
            "\n",
            "Epoch 00002: val_my_iou_metric did not improve from 0.38213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX3KcpQTHTev"
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDICkBm_HVqo",
        "outputId": "ac88178c-498d-456c-9990-b7afb8553301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/35 [00:01<00:43,  1.28s/it]\u001b[A\n",
            "  6%|▌         | 2/35 [00:02<00:42,  1.28s/it]\u001b[A\n",
            "  9%|▊         | 3/35 [00:03<00:40,  1.27s/it]\u001b[A\n",
            " 11%|█▏        | 4/35 [00:05<00:39,  1.27s/it]\u001b[A\n",
            " 14%|█▍        | 5/35 [00:06<00:38,  1.28s/it]\u001b[A\n",
            " 17%|█▋        | 6/35 [00:07<00:36,  1.27s/it]\u001b[A\n",
            " 20%|██        | 7/35 [00:08<00:35,  1.27s/it]\u001b[A\n",
            " 23%|██▎       | 8/35 [00:10<00:34,  1.26s/it]\u001b[A\n",
            " 26%|██▌       | 9/35 [00:11<00:32,  1.26s/it]\u001b[A\n",
            " 29%|██▊       | 10/35 [00:12<00:32,  1.28s/it]\u001b[A\n",
            " 31%|███▏      | 11/35 [00:13<00:30,  1.27s/it]\u001b[A\n",
            " 34%|███▍      | 12/35 [00:15<00:29,  1.27s/it]\u001b[A\n",
            " 37%|███▋      | 13/35 [00:16<00:27,  1.26s/it]\u001b[A\n",
            " 40%|████      | 14/35 [00:17<00:26,  1.28s/it]\u001b[A\n",
            " 43%|████▎     | 15/35 [00:19<00:25,  1.26s/it]\u001b[A\n",
            " 46%|████▌     | 16/35 [00:20<00:23,  1.26s/it]\u001b[A\n",
            " 49%|████▊     | 17/35 [00:21<00:22,  1.26s/it]\u001b[A\n",
            " 51%|█████▏    | 18/35 [00:22<00:21,  1.25s/it]\u001b[A\n",
            " 54%|█████▍    | 19/35 [00:24<00:20,  1.25s/it]\u001b[A\n",
            " 57%|█████▋    | 20/35 [00:25<00:18,  1.25s/it]\u001b[A\n",
            " 60%|██████    | 21/35 [00:26<00:17,  1.25s/it]\u001b[A\n",
            " 63%|██████▎   | 22/35 [00:27<00:16,  1.26s/it]\u001b[A\n",
            " 66%|██████▌   | 23/35 [00:29<00:15,  1.25s/it]\u001b[A\n",
            " 69%|██████▊   | 24/35 [00:30<00:13,  1.24s/it]\u001b[A\n",
            " 71%|███████▏  | 25/35 [00:31<00:12,  1.25s/it]\u001b[A\n",
            " 74%|███████▍  | 26/35 [00:32<00:11,  1.24s/it]\u001b[A\n",
            " 77%|███████▋  | 27/35 [00:34<00:09,  1.25s/it]\u001b[A\n",
            " 80%|████████  | 28/35 [00:35<00:08,  1.25s/it]\u001b[A\n",
            " 83%|████████▎ | 29/35 [00:36<00:07,  1.24s/it]\u001b[A\n",
            " 86%|████████▌ | 30/35 [00:37<00:06,  1.26s/it]\u001b[A\n",
            " 89%|████████▊ | 31/35 [00:39<00:05,  1.26s/it]\u001b[A\n",
            " 91%|█████████▏| 32/35 [00:40<00:03,  1.26s/it]\u001b[A\n",
            " 94%|█████████▍| 33/35 [00:41<00:02,  1.25s/it]\u001b[A\n",
            " 97%|█████████▋| 34/35 [00:42<00:01,  1.24s/it]\u001b[A\n",
            "100%|██████████| 35/35 [00:44<00:00,  1.26s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqAKEaENHXOg",
        "outputId": "99f05b11-8cb1-4137-c3ee-b7548f8ae26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.5363 at threshold: 0.880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.429389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.076660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.314500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.355625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.443125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.496125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.536250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.429389\n",
              "std     0.204939   0.076660\n",
              "min     0.200000   0.314500\n",
              "25%     0.370000   0.355625\n",
              "50%     0.540000   0.443125\n",
              "75%     0.710000   0.496125\n",
              "max     0.880000   0.536250"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaPiq4oMHaHQ",
        "outputId": "01209005-654e-47ca-f213-20ea895b28d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbe23a23be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}